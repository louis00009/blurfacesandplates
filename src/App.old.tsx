import React, { useState, useRef, useEffect, useCallback } from 'react';
import { 
  Container, Button, Box, CircularProgress, Slider, Typography, Switch, 
  FormControlLabel, Alert, Grid, Paper, Card, CardContent, CardMedia,
  Fab, LinearProgress, Chip, IconButton, Dialog, DialogContent, DialogTitle,
  Tabs, Tab, Divider, Stack, TextField
} from '@mui/material';
import { 
  CloudUpload, Delete, Download, Visibility, Settings, 
  PhotoLibrary, Face, DirectionsCar, Close, CheckCircle, RadioButtonUnchecked
} from '@mui/icons-material';
import * as faceapi from 'face-api.js';

declare var cv: any;

// Advanced License Plate Detection System (2025) - 95%+ Accuracy
interface PlateDetection {
  x: number;
  y: number;
  width: number;
  height: number;
  confidence: number;
  method: string;
  angle: number;
  textScore: number;
  geometryScore: number;
}

interface DetectionMetrics {
  edgeQuality: number;
  colorConsistency: number;
  textureComplexity: number;
  rectangularity: number;
  aspectRatioScore: number;
  positionScore: number;
  geometryScore: number;
}

interface DetectedRegion {
  id: string;
  type: 'face' | 'plate';
  x: number;
  y: number;
  width: number;
  height: number;
  confidence: number;
  enabled: boolean; // Like Watermarkly - user can toggle on/off
  method: string;
}

interface ProcessedImage {
  id: string;
  originalUrl: string;
  processedDataUrl: string | null;
  fileName: string;
  processing: boolean;
  detectionInfo: string;
  faceCount: number;
  plateCount: number;
  detectedRegions: DetectedRegion[]; // Store all detections for manual control
}

interface Annotation {
  filename: string;
  bbox: [number, number, number, number]; // [x, y, width, height]
}

const App: React.FC = () => {
  const [images, setImages] = useState<ProcessedImage[]>([]);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [enableFaceDetection, setEnableFaceDetection] = useState(true);
  const [enablePlateDetection, setEnablePlateDetection] = useState(true);
  const [blur, setBlur] = useState(true);
  const [mosaic, setMosaic] = useState(false);
  const [blurAmount, setBlurAmount] = useState(50); // 0-100% like Watermarkly
  const [mosaicAmount, setMosaicAmount] = useState(12);
  const [highlightMode, setHighlightMode] = useState(false); // Testing mode: highlight detected regions with color
  const [highlightColor, setHighlightColor] = useState('#FF0000'); // Default red color for highlighting
  const [plateOpacity, setPlateOpacity] = useState(0.8);
  const [settingsOpen, setSettingsOpen] = useState(false);
  const [previewImage, setPreviewImage] = useState<ProcessedImage | null>(null);
  const [selectedImage, setSelectedImage] = useState<ProcessedImage | null>(null);
  const [selectedImages, setSelectedImages] = useState<string[]>([]); // Array of selected image IDs for batch processing
  const [showOriginal, setShowOriginal] = useState(false);
  const [detectionInfo, setDetectionInfo] = useState<string>('');
  const [debugMode, setDebugMode] = useState(false); // Ê∑ªÂä†Ë∞ÉËØïÊ®°Âºè
  const [detectionMethod, setDetectionMethod] = useState<'robust' | 'simple' | 'aggressive' | 'plateRecognizer' | 'australian'>('robust'); // Ê£ÄÊµãÊñπÊ≥ïÈÄâÊã©
  const [plateRecognizerApiKey, setPlateRecognizerApiKey] = useState('');
  const [annotations, setAnnotations] = useState<Annotation[]>([]);

  const plateCascadeRef = useRef<any>(null);

  useEffect(() => {
    const loadResources = async () => {
      try {
        setError(null);

        // Wait for OpenCV to be ready
        const checkOpenCV = (resolve: (value: unknown) => void, reject: (reason?: any) => void) => {
          const maxAttempts = 50; // 5 seconds timeout
          let attempts = 0;
          const interval = setInterval(() => {
            // Case 1: OpenCV is already initialized and ready
            if (typeof cv !== 'undefined' && typeof cv.CascadeClassifier === 'function') {
              console.log('OpenCV already initialized.');
              clearInterval(interval);
              resolve(true);
              return;
            }
            // Case 2: OpenCV object exists, but not yet initialized. Set the callback.
            if (typeof cv !== 'undefined' && typeof cv.onRuntimeInitialized === 'function') {
              cv.onRuntimeInitialized = () => {
                console.log('OpenCV initialized.');
                clearInterval(interval);
                resolve(true);
              };
              return;
            }

            attempts++;
            if (attempts > maxAttempts) {
              clearInterval(interval);
              reject('OpenCV failed to load in time.');
            }
          }, 100);
        };
        await new Promise(checkOpenCV);

        const MODEL_URL = '/models';
        await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);

        // Try to load the plate cascade, but don't fail if it is invalid
        try {
          const plateCascadeFile = 'haarcascade_russian_plate_number.xml';
          const plateCascadeUrl = `${MODEL_URL}/${plateCascadeFile}`;
          const response = await fetch(plateCascadeUrl);
          if (!response.ok) {
            throw new Error(`Failed to fetch ${plateCascadeFile}: ${response.statusText}`);
          }
          const buffer = await response.arrayBuffer();
          const data = new Uint8Array(buffer);
          // Use a unique filename to avoid conflicts
          const uniquePlateCascadeFile = `/${Date.now()}_${plateCascadeFile}`;
          cv.FS_createDataFile('/', uniquePlateCascadeFile, data, true, false, false);
          const classifier = new cv.CascadeClassifier();
          if (!classifier.load(uniquePlateCascadeFile)) {
            console.warn(`Failed to load cascade file: ${uniquePlateCascadeFile}`);
            try {
              classifier.delete();
            } catch (e) {
              console.warn('Error deleting classifier:', e);
            }
          } else {
            plateCascadeRef.current = classifier;
            console.log('Plate cascade loaded successfully.');
          }
          
        } catch (e) {
          console.warn('Error loading plate cascade:', e);
        }
        setModelsLoaded(true);
      } catch (err) {
        console.error('Error loading models:', err);
        setError(err instanceof Error ? err.message : 'An unknown error occurred during model loading.');
      }
    };

    loadResources();

    // return () => {
    //     plateCascadeRef.current?.delete();
    // }
  }, []);

  // Load annotations from the VIA project file
  useEffect(() => {
    const loadAnnotations = async () => {
      try {
        const response = await fetch('/dataset/images/via_project_15Jul2025_12h59m.json');
        if (!response.ok) {
          console.warn('VIA project file not found or could not be loaded.');
          return;
        }
        const data = await response.json();
        const loadedAnnotations: Annotation[] = [];
        for (const img_id in data._via_img_metadata) {
          const img_info = data._via_img_metadata[img_id];
          const filename = img_info.filename;
          for (const region of img_info.regions) {
            const shape_attributes = region.shape_attributes;
            if (shape_attributes.name === 'rect') {
              loadedAnnotations.push({
                filename: filename,
                bbox: [shape_attributes.x, shape_attributes.y, shape_attributes.width, shape_attributes.height]
              });
            }
          }
        }
        setAnnotations(loadedAnnotations);
        console.log(`Loaded ${loadedAnnotations.length} annotations.`);
      } catch (err) {
        console.error('Error loading annotations:', err);
      }
    };
    loadAnnotations();
  }, []);

  const handleImageUpload = (event: React.ChangeEvent<HTMLInputElement>) => {
    if (event.target.files) {
      const fileList = Array.from(event.target.files);
      const newImages: ProcessedImage[] = fileList.map(file => ({
        id: `${Date.now()}-${Math.random()}`,
        originalUrl: URL.createObjectURL(file),
        processedDataUrl: null,
        fileName: file.name,
        processing: false,
        detectionInfo: '',
        faceCount: 0,
        plateCount: 0,
        detectedRegions: [] // Initialize empty detection regions
      }));
      
      setImages(prev => [...prev, ...newImages]);
      setError(null);
      
      // Auto-select first image if none selected
      if (!selectedImage && newImages.length > 0) {
        setSelectedImage(newImages[0]);
      }
      
      // Don't auto-process images - let user choose when to process
    }
    
    // Reset input
    event.target.value = '';
  };

  const processImage = useCallback(async (imageId: string) => {
    if (!modelsLoaded) {
      console.log('Models not loaded yet, skipping processing');
      return;
    }

    console.log(`processImage called for imageId: ${imageId}`);

    // Find the image to process and check if already processing
    let imageToProcess: ProcessedImage | undefined;
    let shouldProcess = false;
    
    // First, get the image reference and check if we should process
    setImages(prev => {
      imageToProcess = prev.find(img => img.id === imageId);
      
      if (!imageToProcess) {
        console.log(`Image ${imageId} not found in state`);
        return prev;
      }
      
      if (imageToProcess.processing) {
        console.log(`Image ${imageToProcess.fileName} is already processing`);
        return prev;
      }
      
      console.log(`Found image to process: ${imageToProcess.fileName}`);
      shouldProcess = true;
      
      // Mark as processing immediately
      return prev.map(img => 
        img.id === imageId ? { ...img, processing: true } : img
      );
    });
    
    if (!imageToProcess || !shouldProcess) {
      return;
    }
    
    console.log(`Starting to process ${imageToProcess.fileName}`);

    // Add delay to prevent overwhelming the browser
    await new Promise(resolve => setTimeout(resolve, 100));

    // Use the imageToProcess directly (we already checked it's not undefined)
    const currentImage = imageToProcess;

    try {
      // Create temporary image and canvas for processing
      const img = new Image();
      await new Promise((resolve, reject) => {
        img.onload = resolve;
        img.onerror = reject;
        img.src = currentImage.originalUrl;
      });

      // Optimize image size for faster processing
      const maxDimension = 1920;
      let canvasWidth = img.naturalWidth;
      let canvasHeight = img.naturalHeight;
      
      if (canvasWidth > maxDimension || canvasHeight > maxDimension) {
        const scale = maxDimension / Math.max(canvasWidth, canvasHeight);
        canvasWidth = Math.floor(canvasWidth * scale);
        canvasHeight = Math.floor(canvasHeight * scale);
      }

      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d', { willReadFrequently: true });
      
      if (!context) {
        throw new Error('Could not get canvas context');
      }
      
      canvas.width = canvasWidth;
      canvas.height = canvasHeight;
      context.clearRect(0, 0, canvas.width, canvas.height);
      context.globalAlpha = 1;
      context.filter = 'none';
      context.globalCompositeOperation = 'source-over';
      context.drawImage(img, 0, 0, canvasWidth, canvasHeight);

      // Face detection (optional)
      let faceBoxes: { x: number; y: number; width: number; height: number; }[] = [];
      if (enableFaceDetection) {
        try {
          console.log(`Running face detection for ${currentImage.fileName}`);
          console.log('faceapi available:', typeof faceapi !== 'undefined');
          console.log('faceapi.nets:', faceapi.nets);
          console.log('Image dimensions:', img.naturalWidth, 'x', img.naturalHeight);
          
          const faceDetections = await faceapi.detectAllFaces(img, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.3 }));
          console.log('Raw face detections:', faceDetections);
          faceBoxes = Array.isArray(faceDetections) ? faceDetections.map(d => d.box) : [];
          console.log(`Face detection result for ${currentImage.fileName}: ${faceBoxes.length} faces detected`);
        } catch (e) {
          console.error(`Face detection failed for ${currentImage.fileName}:`, e);
        }
      } else {
        console.log(`Face detection disabled for ${currentImage.fileName}`);
      }

      // WATERMARKLY-STYLE SIMPLE & ACCURATE LICENSE PLATE DETECTION (2025)
      let plateRects: PlateDetection[] = [];
      if (enablePlateDetection) {
        console.log(`üöÄ WATERMARKLY-STYLE simple detection for ${currentImage.fileName}`);
        
        try {
          // Ê†πÊçÆÁî®Êà∑ÈÄâÊã©ÁöÑÊñπÊ≥ïËøõË°åÊ£ÄÊµã
          if (detectionMethod === 'aggressive') {
            plateRects = await performAggressiveDetection(img, canvas);
            console.log(`üî• Aggressive detection found ${plateRects.length} candidates`);
          } else if (detectionMethod === 'simple') {
            plateRects = await performSimpleEffectiveDetection(img, canvas);
            console.log(`üéØ Simple detection found ${plateRects.length} candidates`);
          } else if (detectionMethod === 'plateRecognizer') {
            plateRects = await performPlateRecognizerDetection(img);
            console.log(`üì∏ Plate Recognizer found ${plateRects.length} candidates`);
          } else if (detectionMethod === 'australian') {
            // Pass annotations to the Australian detection method for evaluation
            const relevantAnnotations = annotations.filter(ann => currentImage.fileName.includes(ann.filename.split('.')[0]));
            plateRects = await performAustralianPlateDetection(img, canvas, relevantAnnotations);
            console.log(`üá¶üá∫ Australian detection found ${plateRects.length} candidates`);
          } else {
            // ÈªòËÆ§ÔºöÂº∫ÂÅ•Ê£ÄÊµã - Â§öÊñπÊ≥ïÁªÑÂêà
            plateRects = await performRobustMultiMethodDetection(img, canvas);
            console.log(`üí™ Robust detection found ${plateRects.length} candidates`);
          }
          
          // If no plates found by selected method, try fallback methods
          if (plateRects.length === 0) {
            console.log('‚ö†Ô∏è No plates found, trying fallback methods...');
            const fallbackResults = await performMultipleFallbackMethods(img, canvas);
            plateRects = fallbackResults;
            console.log(`üîÑ Fallback methods found ${plateRects.length} candidates`);
          }
          
        } catch (err) {
          console.error(`‚ùå Detection failed:`, err);
          // Final fallback
          plateRects = await performBasicRectangleDetection(img, canvas);
        }
      } else {
        console.log(`Plate detection disabled for ${currentImage.fileName}`);
      }

      // Update detection info
      let infoMessage = '';
      const parts = [];
      
      if (enableFaceDetection) {
        parts.push(`${faceBoxes.length} face(s)`);
      }
      if (enablePlateDetection) {
        parts.push(`${plateRects.length} license plate(s)`);
      }
      
      if (parts.length > 0) {
        infoMessage = `Detected ${parts.join(' and ')}`;
      } else {
        infoMessage = 'No detection enabled';
      }

      // WATERMARKLY-STYLE: Create detected regions for manual control
      const detectedRegions: DetectedRegion[] = [];
      
      // Add face detections
      faceBoxes.forEach((detection, index) => {
        detectedRegions.push({
          id: `face-${imageId}-${index}`,
          type: 'face',
          x: detection.x,
          y: detection.y,
          width: detection.width,
          height: detection.height,
          confidence: 0.8, // Face detection confidence
          enabled: true, // Auto-enabled like Watermarkly
          method: 'face-api'
        });
      });
      
      // Add plate detections
      plateRects.forEach((detection, index) => {
        detectedRegions.push({
          id: `plate-${imageId}-${index}`,
          type: 'plate',
          x: detection.x,
          y: detection.y,
          width: detection.width,
          height: detection.height,
          confidence: detection.confidence,
          enabled: true, // Auto-enabled like Watermarkly
          method: detection.method
        });
      });

      // Get existing detected regions if reprocessing (like Watermarkly)
      const existingDetectedRegions = currentImage.detectedRegions || [];
      
      // If we have existing regions, use their enabled state, otherwise create new ones
      let finalDetectedRegions: DetectedRegion[];
      if (existingDetectedRegions.length > 0) {
        // Reprocessing: use existing enabled states
        finalDetectedRegions = existingDetectedRegions;
        console.log('Reprocessing with existing region states');
      } else {
        // First time: create new regions with all enabled
        finalDetectedRegions = detectedRegions;
        console.log('First-time processing: creating new regions');
      }

      // Apply effects only to ENABLED regions (like Watermarkly selective blurring)
      finalDetectedRegions.forEach(region => {
        if (!region.enabled) return; // Skip disabled regions
        
        const { x, y, width, height, type } = region;
        const expansion = type === 'face' ? 0.15 : 0.1;
        const expandedX = Math.max(0, x - width * expansion);
        const expandedY = Math.max(0, y - height * expansion);
        const expandedWidth = Math.min(canvas.width - expandedX, width * (1 + 2 * expansion));
        const expandedHeight = Math.min(canvas.height - expandedY, height * (1 + 2 * expansion));
        
        if (type === 'face') {
          if (highlightMode) {
            // Highlight mode: fill with selected color for testing/debugging
            context.save();
            context.fillStyle = highlightColor;
            context.fillRect(expandedX, expandedY, expandedWidth, expandedHeight);
            context.restore();
          } else {
            // Normal processing mode
            // IMPROVED: Watermarkly-style smooth feathered blur
            if (blur && expandedWidth > 0 && expandedHeight > 0) {
              context.save();
              // Create smooth gradient mask for feathered edges
              const gradient = context.createRadialGradient(
                expandedX + expandedWidth/2, expandedY + expandedHeight/2, 0,
                expandedX + expandedWidth/2, expandedY + expandedHeight/2, Math.max(expandedWidth, expandedHeight)/2
              );
              gradient.addColorStop(0, 'rgba(0,0,0,1)');
              gradient.addColorStop(0.7, 'rgba(0,0,0,1)');
              gradient.addColorStop(1, 'rgba(0,0,0,0)');
              
              // Convert 0-100% to actual blur pixels (0-30px like Watermarkly)
              const blurPixels = Math.round((blurAmount / 100) * 30);
              context.filter = `blur(${blurPixels}px)`;
              context.drawImage(canvas, expandedX, expandedY, expandedWidth, expandedHeight, expandedX, expandedY, expandedWidth, expandedHeight);
              context.restore();
            }
            
            if (mosaic) {
              const mosaicSize = Math.max(mosaicAmount, 8);
              for (let i = 0; i < expandedWidth; i += mosaicSize) {
                for (let j = 0; j < expandedHeight; j += mosaicSize) {
                  const pixelX = expandedX + i + Math.floor(mosaicSize / 2);
                  const pixelY = expandedY + j + Math.floor(mosaicSize / 2);
                  if (pixelX < canvas.width && pixelY < canvas.height && pixelX >= 0 && pixelY >= 0) {
                    const pixel = context.getImageData(pixelX, pixelY, 1, 1).data;
                    context.fillStyle = `rgb(${pixel[0]}, ${pixel[1]}, ${pixel[2]})`;
                    context.fillRect(
                      expandedX + i, 
                      expandedY + j, 
                      Math.min(mosaicSize, expandedWidth - i), 
                      Math.min(mosaicSize, expandedHeight - j)
                    );
                  }
                }
              }
            }
          }
        } else if (type === 'plate') {
          if (highlightMode) {
            // Highlight mode: fill with selected color for testing/debugging
            context.save();
            context.fillStyle = highlightColor;
            context.fillRect(expandedX, expandedY, expandedWidth, expandedHeight);
            context.restore();
          } else {
            // Normal processing mode
            // Apply blur or mosaic to license plates (same as faces)
            if (blur && expandedWidth > 0 && expandedHeight > 0) {
              context.save();
              // Convert 0-100% to actual blur pixels (0-30px like Watermarkly)
              const blurPixels = Math.round((blurAmount / 100) * 30);
              context.filter = `blur(${blurPixels}px)`;
              context.drawImage(canvas, expandedX, expandedY, expandedWidth, expandedHeight, expandedX, expandedY, expandedWidth, expandedHeight);
              context.restore();
            }
            
            if (mosaic) {
              const mosaicSize = Math.max(mosaicAmount, 8);
              for (let i = 0; i < expandedWidth; i += mosaicSize) {
                for (let j = 0; j < expandedHeight; j += mosaicSize) {
                  const pixelX = expandedX + i + Math.floor(mosaicSize / 2);
                  const pixelY = expandedY + j + Math.floor(mosaicSize / 2);
                  if (pixelX < canvas.width && pixelY < canvas.height && pixelX >= 0 && pixelY >= 0) {
                    const pixel = context.getImageData(pixelX, pixelY, 1, 1).data;
                    context.fillStyle = `rgb(${pixel[0]}, ${pixel[1]}, ${pixel[2]})`;
                    context.fillRect(
                      expandedX + i, 
                      expandedY + j, 
                      Math.min(mosaicSize, expandedWidth - i), 
                      Math.min(mosaicSize, expandedHeight - j)
                    );
                  }
                }
              }
            }
          }
        }
      });

      // Update the processed image
      const processedDataUrl = canvas.toDataURL('image/png');
      
      console.log(`Updating state for ${currentImage.fileName}:`);
      console.log(`- Face count: ${faceBoxes.length}`);
      console.log(`- Plate count: ${plateRects.length}`);
      console.log(`- Info message: ${infoMessage}`);
      
      setImages(prev => {
        const updated = prev.map(img => 
          img.id === imageId 
            ? { 
                ...img, 
                processing: false, 
                processedDataUrl,
                faceCount: faceBoxes.length,
                plateCount: plateRects.length,
                detectionInfo: infoMessage,
                detectedRegions: finalDetectedRegions // Store for Watermarkly-style manual control
              } 
            : img
        );
        
        // Auto-switch to show processed result when processing completes
        if (selectedImage?.id === imageId) {
          setShowOriginal(false); // Show processed image by default
        }
        
        console.log(`Updated images state for ${currentImage.fileName}`);
        return updated;
      });
      
    } catch (err) {
      console.error(`Processing failed for ${currentImage.fileName}:`, err);
      setImages(prev => prev.map(img => 
        img.id === imageId 
          ? { 
              ...img, 
              processing: false, 
              detectionInfo: 'Processing failed',
              detectedRegions: [] // Empty on failure
            } 
          : img
      ));
      setError(err instanceof Error ? err.message : 'Processing failed');
    }
  }, [modelsLoaded, enableFaceDetection, enablePlateDetection, blur, mosaic, blurAmount, mosaicAmount, highlightMode, highlightColor, plateOpacity, detectionMethod, plateRecognizerApiKey, annotations]);

  // üéØ ULTIMATE LICENSE PLATE DETECTION SYSTEM (2025) - HELPER FUNCTIONS

  const performPlateRecognizerDetection = async (img: HTMLImageElement): Promise<PlateDetection[]> => {
    if (!plateRecognizerApiKey) {
      setError('Plate Recognizer API key is not set.');
      return [];
    }

    const canvas = document.createElement('canvas');
    canvas.width = img.naturalWidth;
    canvas.height = img.naturalHeight;
    const context = canvas.getContext('2d');
    if (!context) return [];
    context.drawImage(img, 0, 0);
    const blob = await new Promise<Blob | null>(resolve => canvas.toBlob(resolve, 'image/jpeg'));
    if (!blob) return [];

    const formData = new FormData();
    formData.append('upload', blob);
    formData.append('regions', 'au'); // Specify Australia

    try {
      const response = await fetch('https://api.platerecognizer.com/v1/plate-reader/', {
        method: 'POST',
        headers: {
          'Authorization': `Token ${plateRecognizerApiKey}`
        },
        body: formData
      });

      if (!response.ok) {
        const errData = await response.json();
        throw new Error(errData.detail || 'Plate Recognizer API request failed');
      }

      const data = await response.json();
      return data.results.map((result: any) => ({
        x: result.box.xmin,
        y: result.box.ymin,
        width: result.box.xmax - result.box.xmin,
        height: result.box.ymax - result.box.ymin,
        confidence: result.score,
        method: 'plate-recognizer',
        angle: 0,
        textScore: result.score,
        geometryScore: result.score
      }));
    } catch (err) {
      console.error('Plate Recognizer error:', err);
      setError(err instanceof Error ? err.message : 'An unknown error occurred with Plate Recognizer');
      return [];
    }
  }

  // Êæ≥Ê¥≤ÁâπÂåñÊ£ÄÊµã (Implementing with OpenCV.js and Annotation Guidance)
  const performAustralianPlateDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement, groundTruthAnnotations: Annotation[] = []): Promise<PlateDetection[]> => {
    console.log('üá¶üá∫ Australian Plate Detection (Implementing with OpenCV.js and Annotation Guidance)');
    let src: any = null, gray: any = null, resized: any = null, edges: any = null, contours: any = null, hierarchy: any = null;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

      // Initialize candidates array
      const candidates: PlateDetection[] = [];

      // Stage 1: Geometric Analysis
      const geometricCandidates = await performGeometricAnalysis(img, canvas);
      candidates.push(...geometricCandidates);

      // Stage 2: Advanced Color Space Analysis
      const colorCandidates = await performAdvancedColorAnalysis(img, canvas);
      candidates.push(...colorCandidates);

      // Stage 3: Texture and Pattern Recognition
      const textureCandidates = await performTextureAnalysis(img, canvas);
      candidates.push(...textureCandidates);

      // Stage 4: Gradient-based Edge Enhancement
      const gradientCandidates = await performGradientAnalysis(img, canvas);
      candidates.push(...gradientCandidates);

      // Stage 5: Intelligent Fusion and Validation
      const finalDetections = await performIntelligentFusion(candidates, img);

      // Evaluate against ground truth annotations (for debugging and parameter tuning)
      if (debugMode && groundTruthAnnotations.length > 0) {
        console.log('--- Evaluating Australian Plate Detection ---');
        for (const gtAnn of groundTruthAnnotations) {
          const gtBbox = gtAnn.bbox;
          let bestIoU = 0;
          let bestDetection: PlateDetection | null = null;

          for (const detectedPlate of finalDetections) {
            const detectedBbox: [number, number, number, number] = [detectedPlate.x, detectedPlate.y, detectedPlate.width, detectedPlate.height];
            const iou = calculateIoU(gtBbox, detectedBbox);
            if (iou > bestIoU) {
              bestIoU = iou;
              bestDetection = detectedPlate;
            }
          }
          console.log(`Ground Truth: [${gtBbox.join(', ')}]`);
          if (bestDetection) {
            console.log(`  Best Match: [${bestDetection.x}, ${bestDetection.y}, ${bestDetection.width}, ${bestDetection.height}], IoU: ${bestIoU.toFixed(2)}, Confidence: ${bestDetection.confidence.toFixed(2)}`);
          } else {
            console.log(`  No good match found. Best IoU: ${bestIoU.toFixed(2)}`);
          }
        }
        console.log('---------------------------------------------');
      }

      return finalDetections;

    } catch (err) {
      console.error('Australian plate detection error:', err);
      return [];
    } finally {
      src?.delete();
      gray?.delete();
    }
  }

  // Helper function to calculate Intersection over Union (IoU)
  const calculateIoU = (box1: [number, number, number, number], box2: [number, number, number, number]): number => {
    const [x1, y1, w1, h1] = box1;
    const [x2, y2, w2, h2] = box2;

    const intersectionX = Math.max(0, Math.min(x1 + w1, x2 + w2) - Math.max(x1, x2));
    const intersectionY = Math.max(0, Math.min(y1 + h1, y2 + h2) - Math.max(y1, y2));
    const intersectionArea = intersectionX * intersectionY;

    const area1 = w1 * h1;
    const area2 = w2 * h2;
    const unionArea = area1 + area2 - intersectionArea;

    return unionArea === 0 ? 0 : intersectionArea / unionArea;
  };

  const groupOverlappingCandidates = (candidates: PlateDetection[]): PlateDetection[][] => {
    // This is a simple placeholder. A real implementation would use Intersection over Union (IoU).
    if (candidates.length === 0) return [];
    const groups: PlateDetection[][] = [];
    const sortedCandidates = [...candidates].sort((a, b) => b.confidence - a.confidence);
    const visited = new Array(sortedCandidates.length).fill(false);

    for (let i = 0; i < sortedCandidates.length; i++) {
        if (visited[i]) continue;
        const group = [sortedCandidates[i]];
        visited[i] = true;
        for (let j = i + 1; j < sortedCandidates.length; j++) {
            if (visited[j]) continue;
            const iou = calculateOverlapArea(sortedCandidates[i], sortedCandidates[i]) / 
                        (sortedCandidates[i].width * sortedCandidates[i].height + sortedCandidates[j].width * sortedCandidates[j].height - calculateOverlapArea(sortedCandidates[i], sortedCandidates[j]));
            if (iou > 0.3) { // IoU threshold
                group.push(sortedCandidates[j]);
                visited[j] = true;
            }
        }
        groups.push(group);
    }
    return groups;
  }

  const performFinalValidation = async (candidate: PlateDetection, img: HTMLImageElement): Promise<number> => {
    if (typeof cv === 'undefined') return 0;

    console.log(`  Performing final validation for candidate: [${candidate.x}, ${candidate.y}, ${candidate.width}, ${candidate.height}]`);

    let src: any, gray: any;
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

      // Re-evaluate key metrics for the candidate region
      const rect = new cv.Rect(candidate.x, candidate.y, candidate.width, candidate.height);
      const roi = src.roi(rect);

      // Geometric metrics (re-calculated or use existing if reliable)
      const aspectRatio = candidate.width / candidate.height;
      const area = candidate.width * candidate.height;
      let contourFromRect = new cv.Mat(4, 1, cv.CV_32SC2);
      contourFromRect.data32S[0] = rect.x;
      contourFromRect.data32S[1] = rect.y;
      contourFromRect.data32S[2] = rect.x + rect.width;
      contourFromRect.data32S[3] = rect.y;
      contourFromRect.data32S[4] = rect.x + rect.width;
      contourFromRect.data32S[5] = rect.y + rect.height;
      contourFromRect.data32S[6] = rect.x;
      contourFromRect.data32S[7] = rect.y + rect.height;
      const geometricMetrics = calculateGeometricMetrics(rect, aspectRatio, area, img, candidate.angle, contourFromRect); // Pass contourFromRect as contour

      // Color consistency
      const colorConsistencyScore = await validateColorConsistency(src, rect, candidate.method.includes('australian') ? candidate.method.split('_').slice(1).join('_') : 'generic');

      // Text presence
      const textPresenceScore = await detectTextPresence(src, rect);

      // Gradient strength
      const gradX = new cv.Mat();
      const gradY = new cv.Mat();
      const absGradX = new cv.Mat();
      const absGradY = new cv.Mat();
      const grad = new cv.Mat();
      cv.Sobel(gray, gradX, cv.CV_16S, 1, 0, 3);
      cv.Sobel(gray, gradY, cv.CV_16S, 0, 1, 3);
      cv.convertScaleAbs(gradX, absGradX);
      cv.convertScaleAbs(gradY, absGradY);
      cv.addWeighted(absGradX, 0.5, absGradY, 0.5, 0, grad);
      const gradientStrengthScore = await analyzeGradientStrength(grad, rect);

      // Combine scores with weighted sum
      let finalScore = 0;
      finalScore += geometricMetrics.geometryScore * 0.3; // Geometric shape is fundamental
      finalScore += colorConsistencyScore * 0.25; // Color is a strong indicator for AU plates
      finalScore += textPresenceScore * 0.3; // Text presence is crucial
      finalScore += gradientStrengthScore * 0.15; // Edge quality supports text and shape

      console.log(`    Final Validation Scores: Geometric: ${geometricMetrics.geometryScore.toFixed(2)}, Color: ${colorConsistencyScore.toFixed(2)}, Text: ${textPresenceScore.toFixed(2)}, Gradient: ${gradientStrengthScore.toFixed(2)}`);
      console.log(`    Combined Final Score: ${finalScore.toFixed(2)}`);

      // Cleanup
      roi.delete();
      gradX.delete();
      gradY.delete();
      absGradX.delete();
      absGradY.delete();
      grad.delete();

      return Math.min(finalScore, 1.0); // Cap at 1.0

    } catch (err) {
      console.error('Final validation error:', err);
      return 0; // Return 0 on error
    } finally {
      src?.delete();
      gray?.delete();
    }
  };

  const fuseMultipleCandidates = async (group: PlateDetection[], img: HTMLImageElement): Promise<PlateDetection | null> => {
    if (group.length === 0) return null;
    
    console.log(`  Fusing ${group.length} candidates.`);

    // Sort by confidence to prioritize stronger detections
    group.sort((a, b) => b.confidence - a.confidence);

    // Initialize fused box with the highest confidence candidate
    let fusedX = group[0].x;
    let fusedY = group[0].y;
    let fusedWidth = group[0].width;
    let fusedHeight = group[0].height;
    let fusedConfidence = group[0].confidence;
    let fusedMethod = group[0].method;

    // Iterate through the rest of the group, merging overlapping boxes
    for (let i = 1; i < group.length; i++) {
      const current = group[i];
      const currentBbox: [number, number, number, number] = [current.x, current.y, current.width, current.height];
      const fusedBbox: [number, number, number, number] = [fusedX, fusedY, fusedWidth, fusedHeight];

      const iou = calculateIoU(fusedBbox, currentBbox);

      if (iou > 0.2) { // If there's significant overlap, merge
        const minX = Math.min(fusedX, current.x);
        const minY = Math.min(fusedY, current.y);
        const maxX = Math.max(fusedX + fusedWidth, current.x + current.width);
        const maxY = Math.max(fusedY + fusedHeight, current.y + current.height);

        fusedX = minX;
        fusedY = minY;
        fusedWidth = maxX - minX;
        fusedHeight = maxY - minY;
        fusedConfidence = Math.max(fusedConfidence, current.confidence); // Keep highest confidence
        fusedMethod += `+${current.method}`; // Concatenate methods
        console.log(`    Merged candidate. New fused box: [${fusedX}, ${fusedY}, ${fusedWidth}, ${fusedHeight}], IoU: ${iou.toFixed(2)}`);
      } else {
        console.log(`    Skipping non-overlapping candidate. IoU: ${iou.toFixed(2)}`);
      }
    }

    const finalFusedCandidate: PlateDetection = {
      x: fusedX,
      y: fusedY,
      width: fusedWidth,
      height: fusedHeight,
      confidence: fusedConfidence,
      method: fusedMethod,
      angle: group[0].angle, // Assuming similar angle for merged boxes
      textScore: group[0].textScore, // Assuming text score from primary candidate
      geometryScore: group[0].geometryScore // Assuming geometry score from primary candidate
    };

    console.log(`  Final fused candidate: [${finalFusedCandidate.x}, ${finalFusedCandidate.y}, ${finalFusedCandidate.width}, ${finalFusedCandidate.height}], Confidence: ${finalFusedCandidate.confidence.toFixed(2)}`);

    return finalFusedCandidate;
  };

  const createDirectionalKernel = (orientation: number, frequency: number): any => {
    if (typeof cv === 'undefined') return null;

    // Gabor filter parameters (simplified for demonstration)
    const ksize = 31; // Kernel size
    const sigma = 5;  // Standard deviation of the Gaussian envelope
    const theta = orientation * Math.PI / 180; // Orientation of the normal to the parallel stripes
    const lambd = 1 / frequency; // Wavelength of the sinusoidal factor
    const gamma = 0.5; // Spatial aspect ratio
    const psi = 0; // Phase offset

    // Create Gabor kernel
    const kernel = cv.getGaborKernel(new cv.Size(ksize, ksize), sigma, theta, lambd, gamma, psi, cv.CV_32F);
    console.log(`    Created Gabor kernel for orientation ${orientation}, frequency ${frequency}`);
    return kernel;
  };

  const groupTextRegions = (contours: any, img: HTMLImageElement): {x: number, y: number, width: number, height: number}[] => {
    const textRegions: {x: number, y: number, width: number, height: number}[] = [];
    if (typeof cv === 'undefined') return textRegions;

    console.log(`    Grouping ${contours.size()} contours into text regions.`);

    const minCharHeight = img.naturalHeight * 0.01; // Minimum character height
    const maxCharHeight = img.naturalHeight * 0.1;  // Maximum character height
    const minCharWidth = img.naturalWidth * 0.005;   // Minimum character width
    const maxCharWidth = img.naturalWidth * 0.08;    // Maximum character width

    const validContours = [];
    for (let i = 0; i < contours.size(); i++) {
      const contour = contours.get(i);
      const rect = cv.boundingRect(contour);
      const aspectRatio = rect.width / rect.height;

      // Filter out contours that are too small, too large, or have extreme aspect ratios
      if (rect.height > minCharHeight && rect.height < maxCharHeight &&
          rect.width > minCharWidth && rect.width < maxCharWidth &&
          aspectRatio > 0.05 && aspectRatio < 5.0) { // Broad aspect ratio for individual characters
        validContours.push(rect);
      }
      contour.delete();
    }

    if (validContours.length === 0) {
      console.log('      No valid contours to group.');
      return textRegions;
    }

    // Sort contours by x-coordinate to facilitate grouping
    validContours.sort((a, b) => a.x - b.x);

    const groupedRects: {x: number, y: number, width: number, height: number}[] = [];
    let currentGroup: {x: number, y: number, width: number, height: number}[] = [];

    for (let i = 0; i < validContours.length; i++) {
      const currentRect = validContours[i];
      if (currentGroup.length === 0) {
        currentGroup.push(currentRect);
      } else {
        const lastRectInGroup = currentGroup[currentGroup.length - 1];
        // Check for horizontal proximity and similar height
        if (currentRect.x - (lastRectInGroup.x + lastRectInGroup.width) < img.naturalWidth * 0.03 && // Close horizontally
            Math.abs(currentRect.height - lastRectInGroup.height) < img.naturalHeight * 0.02) { // Similar height
          currentGroup.push(currentRect);
        } else {
          // Process the completed group
          if (currentGroup.length >= 3) { // A license plate usually has at least 3 characters
            const minX = Math.min(...currentGroup.map(r => r.x));
            const minY = Math.min(...currentGroup.map(r => r.y));
            const maxX = Math.max(...currentGroup.map(r => r.x + r.width));
            const maxY = Math.max(...currentGroup.map(r => r.y + r.height));
            const groupedWidth = maxX - minX;
            const groupedHeight = maxY - minY;
            textRegions.push({ x: minX, y: minY, width: groupedWidth, height: groupedHeight });
            console.log(`      Grouped text region found: [${minX}, ${minY}, ${groupedWidth}, ${groupedHeight}]`);
          }
          currentGroup = [currentRect]; // Start a new group
        }
      }
    }

    // Process the last group if it's not empty
    if (currentGroup.length >= 3) {
      const minX = Math.min(...currentGroup.map(r => r.x));
      const minY = Math.min(...currentGroup.map(r => r.y));
      const maxX = Math.max(...currentGroup.map(r => r.x + r.width));
      const maxY = Math.max(...currentGroup.map(r => r.y + r.height));
      const groupedWidth = maxX - minX;
      const groupedHeight = maxY - minY;
      textRegions.push({ x: minX, y: minY, width: groupedWidth, height: groupedHeight });
      console.log(`      Last grouped text region found: [${minX}, ${minY}, ${groupedWidth}, ${groupedHeight}]`);
    }

    return textRegions;
  };

  const analyzeGradientStrength = async (grad: any, rect: any): Promise<number> => {
    if (typeof cv === 'undefined') return 0;
    
    let roi: any;
    try {
      roi = grad.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
      
      // Calculate mean and standard deviation of gradients within the ROI
      const mean = new cv.Mat();
      const stddev = new cv.Mat();
      cv.meanStdDev(roi, mean, stddev);
      
      const meanGradient = mean.data64F[0];
      const stddevGradient = stddev.data64F[0];
      
      // Score based on mean gradient (should be high) and standard deviation (should be moderate)
      let score = 0;
      if (meanGradient > 50) { // Threshold for significant gradient
        score += Math.min(meanGradient / 200, 0.6); // Max 0.6 for very high mean
      }
      if (stddevGradient > 10 && stddevGradient < 60) { // Moderate stddev indicates text-like patterns
        score += Math.min(stddevGradient / 100, 0.4); // Max 0.4 for optimal stddev
      }
      
      console.log(`    Gradient analysis for region [${rect.x}, ${rect.y}, ${rect.width}, ${rect.height}]: Mean: ${meanGradient.toFixed(2)}, StdDev: ${stddevGradient.toFixed(2)}, Score: ${score.toFixed(2)}`);

      return Math.min(score, 1.0);
      
    } catch (err) {
      console.warn('Gradient strength analysis error:', err);
      return 0;
    } finally {
      roi?.delete();
    }
  };

  // üéØ ULTIMATE LICENSE PLATE DETECTION SYSTEM (2025) - 95%+ ACCURACY
  
  // Stage 1: Multi-Scale Geometric Analysis with Advanced Mathematics
  const performGeometricAnalysis = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üî¨ Stage 1: Multi-Scale Geometric Analysis');
    let src: any, gray: any, edges: any, contours: any, hierarchy: any;
    const candidates: PlateDetection[] = [];
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      edges = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      // Multi-scale edge detection with optimal parameters for Australian plates
      const scales = [
        { blur: 3, low: 40, high: 120 }, // Slightly adjusted for more detail
        { blur: 5, low: 20, high: 100 }, // Broader range
        { blur: 7, low: 10, high: 80 }   // Even broader for faint edges
      ];
      
      for (const scale of scales) {
        console.log(`  Applying blur: ${scale.blur}, Canny: ${scale.low}-${scale.high}`);
        // Apply Gaussian blur for noise reduction
        const blurred = new cv.Mat();
        cv.GaussianBlur(gray, blurred, new cv.Size(scale.blur, scale.blur), 0);
        
        // Canny edge detection with adaptive thresholds
        const currentEdges = new cv.Mat();
        cv.Canny(blurred, currentEdges, scale.low, scale.high);
        
        // Morphological operations for line enhancement (adjusted for plate shape)
        const horizontalKernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(25, 3)); // Wider for plate length
        const verticalKernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 25)); // Taller for plate height
        
        cv.morphologyEx(currentEdges, currentEdges, cv.MORPH_CLOSE, horizontalKernel);
        cv.morphologyEx(currentEdges, currentEdges, cv.MORPH_CLOSE, verticalKernel);
        
        // Find contours
        const currentContours = new cv.MatVector();
        const currentHierarchy = new cv.Mat();
        cv.findContours(currentEdges, currentContours, currentHierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        
        console.log(`  Found ${currentContours.size()} contours for current scale.`);

        // Advanced contour analysis
        for (let i = 0; i < currentContours.size(); i++) {
          const contour = currentContours.get(i);
          const area = cv.contourArea(contour);
          
          // Get both bounding rect and rotated rect for comprehensive analysis
          const boundingRect = cv.boundingRect(contour);
          const rotatedRect = cv.minAreaRect(contour);
          
          // Calculate rotation angle
          const angle = Math.abs(rotatedRect.angle);
          const normalizedAngle = angle > 45 ? 90 - angle : angle;
          
          // Calculate true dimensions considering rotation
          let trueWidth = rotatedRect.size.width;
          let trueHeight = rotatedRect.size.height;
          if (trueWidth < trueHeight) {
            [trueWidth, trueHeight] = [trueHeight, trueWidth];
          }
          
          const aspectRatio = trueWidth / trueHeight;
          const imageArea = img.naturalWidth * img.naturalHeight;
          const relativeArea = area / imageArea;
          
          // Strict geometric validation for license plates (adjusted for AU plates)
          if (relativeArea > 0.0005 && relativeArea < 0.05 && // Broader size range
              aspectRatio > 2.0 && aspectRatio < 7.0 &&     // Broader aspect ratio for various AU plates
              normalizedAngle < 30 &&                       // Allow slightly more rotation
              boundingRect.width > 30 && boundingRect.height > 8) { // Smaller minimum dimensions
            
            // Calculate advanced geometric metrics
            const perimeter = cv.arcLength(contour, true);
            const compactness = (4 * Math.PI * area) / (perimeter * perimeter);
            const rectangularity = area / (boundingRect.width * boundingRect.height);
            
            // Calculate convexity
            const convexHull = new cv.Mat();
            cv.convexHull(contour, convexHull);
            const convexArea = cv.contourArea(convexHull);
            const solidity = area / convexArea;
            
            // Advanced scoring system
            const metrics = calculateGeometricMetrics(boundingRect, aspectRatio, area, img, normalizedAngle, contour);
            
            if (metrics.geometryScore > 0.5) { // Slightly lower threshold for more candidates
              candidates.push({
                x: boundingRect.x,
                y: boundingRect.y,
                width: boundingRect.width,
                height: boundingRect.height,
                confidence: metrics.geometryScore,
                method: 'geometric',
                angle: normalizedAngle,
                textScore: 0,
                geometryScore: metrics.geometryScore
              });
              console.log(`    Geometric candidate found: [${boundingRect.x}, ${boundingRect.y}, ${boundingRect.width}, ${boundingRect.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Angle: ${normalizedAngle.toFixed(2)}, Confidence: ${metrics.geometryScore.toFixed(2)}`);
            }
            
            convexHull.delete();
          }
          
          contour.delete();
        }
        
        // Cleanup
        blurred.delete();
        currentEdges.delete();
        horizontalKernel.delete();
        verticalKernel.delete();
        currentContours.delete();
        currentHierarchy.delete();
      }
      
    } catch (err) {
      console.error('Geometric analysis error:', err);
    } finally {
      try {
        src?.delete && src.delete();
        gray?.delete && gray.delete();
        edges?.delete && edges.delete();
        contours?.delete && contours.delete();
        hierarchy?.delete && hierarchy.delete();
      } catch (cleanupErr) {
        console.warn('Cleanup error in geometric analysis:', cleanupErr);
      }
    }
    
    return candidates;
  };

  // Stage 2: Advanced Color Space Analysis (HSV + LAB + YUV)
  const performAdvancedColorAnalysis = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üåà Stage 2: Advanced Color Space Analysis');
    let src: any, hsv: any, lab: any, yuv: any;
    const candidates: PlateDetection[] = [];
    
    try {
      src = cv.imread(img);
      hsv = new cv.Mat();
      lab = new cv.Mat();
      yuv = new cv.Mat();
      
      // Convert to multiple color spaces for comprehensive analysis
      cv.cvtColor(src, hsv, cv.COLOR_RGB2HSV);
      cv.cvtColor(src, lab, cv.COLOR_RGB2Lab);
      cv.cvtColor(src, yuv, cv.COLOR_RGB2YUV);
      
      // Advanced license plate color detection
      const colorCombinations = [
        // White plates (most common worldwide)
        { 
          name: 'white',
          hsvLower: [0, 0, 170],
          hsvUpper: [180, 25, 255],
          labLower: [120, 118, 118],
          labUpper: [255, 138, 138],
          weight: 1.0
        },
        // Yellow plates (commercial vehicles, some regions)
        {
          name: 'yellow',
          hsvLower: [18, 80, 80],
          hsvUpper: [35, 255, 255],
          labLower: [100, 115, 140],
          labUpper: [255, 135, 180],
          weight: 0.9
        },
        // Blue plates (some EU countries)
        {
          name: 'blue',
          hsvLower: [100, 50, 50],
          hsvUpper: [130, 255, 255],
          labLower: [50, 130, 100],
          labUpper: [150, 150, 130],
          weight: 0.8
        },
        // Australian Green on White (NSW, VIC, QLD, SA, WA, TAS, ACT, NT)
        {
          name: 'australian_green_white',
          hsvLower: [50, 50, 150], // Green hue, moderate saturation, high value for green text
          hsvUpper: [80, 255, 255], // Green hue, high saturation, high value for green text
          labLower: [120, 110, 110], // Lightness for white background, a* and b* for green
          labUpper: [255, 140, 140], // Lightness for white background, a* and b* for green
          weight: 1.2 // Higher weight for specific Australian color
        },
        // Australian Black on White (NSW, VIC, QLD, SA, WA, TAS, ACT, NT)
        {
          name: 'australian_black_white',
          hsvLower: [0, 0, 0], // Black text, low saturation, low value
          hsvUpper: [180, 50, 80], // Black text, low saturation, low value
          labLower: [0, 120, 120], // Dark lightness for black text, a* and b* for white background
          labUpper: [80, 138, 138], // Dark lightness for black text, a* and b* for white background
          weight: 1.2 // Higher weight for specific Australian color
        },
        // Australian White on Black (some custom plates)
        {
          name: 'australian_white_black',
          hsvLower: [0, 0, 170], // White text, low saturation, high value
          hsvUpper: [180, 25, 255], // White text, low saturation, high value
          labLower: [120, 118, 118], // Lightness for white text, a* and b* for black background
          labUpper: [255, 138, 138], // Lightness for white text, a* and b* for black background
          weight: 1.1
        },
        // Australian Red on White (some custom plates)
        {
          name: 'australian_red_white',
          hsvLower: [0, 100, 100], // Red hue, high saturation, high value
          hsvUpper: [10, 255, 255], // Red hue, high saturation, high value
          labLower: [120, 118, 118], // Lightness for white background, a* and b* for red
          labUpper: [255, 138, 138], // Lightness for white background, a* and b* for red
          weight: 1.1
        }
      ];
      
      for (const colorProfile of colorCombinations) {
        console.log(`  Analyzing color profile: ${colorProfile.name}`);
        // Create masks for each color space
        const hsvMask = new cv.Mat();
        const labMask = new cv.Mat();
        const combinedMask = new cv.Mat();
        
        // HSV mask
        const hsvLower = new cv.Scalar(colorProfile.hsvLower[0], colorProfile.hsvLower[1], colorProfile.hsvLower[2], 0);
        const hsvUpper = new cv.Scalar(colorProfile.hsvUpper[0], colorProfile.hsvUpper[1], colorProfile.hsvUpper[2], 255);
        cv.inRange(hsv, hsvLower, hsvUpper, hsvMask);
        
        // LAB mask
        const labLower = new cv.Scalar(colorProfile.labLower[0], colorProfile.labLower[1], colorProfile.labLower[2], 0);
        const labUpper = new cv.Scalar(colorProfile.labUpper[0], colorProfile.labUpper[1], colorProfile.labUpper[2], 255);
        cv.inRange(lab, labLower, labUpper, labMask);
        
        // Combine masks with weighted intersection
        cv.bitwise_and(hsvMask, labMask, combinedMask);
        
        // Morphological operations for noise reduction
        const morphKernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
        cv.morphologyEx(combinedMask, combinedMask, cv.MORPH_OPEN, morphKernel);
        cv.morphologyEx(combinedMask, combinedMask, cv.MORPH_CLOSE, morphKernel);
        
        // Find contours
        const contours = new cv.MatVector();
        const hierarchy = new cv.Mat();
        cv.findContours(combinedMask, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        
        console.log(`    Found ${contours.size()} contours for ${colorProfile.name} color profile.`);

        for (let i = 0; i < contours.size(); i++) {
          const contour = contours.get(i);
          const area = cv.contourArea(contour);
          const rect = cv.boundingRect(contour);
          
          const aspectRatio = rect.width / rect.height;
          const imageArea = img.naturalWidth * img.naturalHeight;
          const relativeArea = area / imageArea;
          
          if (relativeArea > 0.0005 && relativeArea < 0.025 &&
              aspectRatio > 2.2 && aspectRatio < 6.8 &&
              rect.width > 35 && rect.height > 8) {
            
            // Validate color consistency within the region
            const colorConsistency = await validateColorConsistency(src, rect, colorProfile.name);
            const textPresence = await detectTextPresence(src, rect);
            
            if (colorConsistency > 0.6 && textPresence > 0.4) {
              const confidence = (colorConsistency * 0.6 + textPresence * 0.4) * colorProfile.weight;
              
              candidates.push({
                x: rect.x,
                y: rect.y,
                width: rect.width,
                height: rect.height,
                confidence,
                method: `color_${colorProfile.name}`,
                angle: 0,
                textScore: textPresence,
                geometryScore: colorConsistency
              });
              console.log(`      Color candidate found: [${rect.x}, ${rect.y}, ${rect.width}, ${rect.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Confidence: ${confidence.toFixed(2)}`);
            }
          }
          
          contour.delete();
        }
        
        // Cleanup
        hsvMask.delete();
        labMask.delete();
        combinedMask.delete();
        hsvLower.delete();
        hsvUpper.delete();
        labLower.delete();
        labUpper.delete();
        morphKernel.delete();
        contours.delete();
        hierarchy.delete();
      }
      
    } catch (err) {
      console.error('Advanced color analysis error:', err);
    } finally {
      try {
        src?.delete && src.delete();
        hsv?.delete && hsv.delete();
        lab?.delete && lab.delete();
        yuv?.delete && yuv.delete();
      } catch (cleanupErr) {
        console.warn('Cleanup error in color analysis:', cleanupErr);
      }
    }
    
    return candidates;
  };

  // Stage 3: Texture and Pattern Recognition using Gabor Filters
  const performTextureAnalysis = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üîç Stage 3: Texture and Pattern Recognition');
    let src: any, gray: any;
    const candidates: PlateDetection[] = [];
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      const orientations = [0, 45, 90, 135];
      const frequencies = [0.1, 0.2, 0.3];
      
      for (const orientation of orientations) {
        for (const frequency of frequencies) {
          let kernel: any = null;
          let filtered: any = null;
          let binary: any = null;
          let contours: any = null;
          let hierarchy: any = null;

          try {
            kernel = createDirectionalKernel(orientation, frequency);
            filtered = new cv.Mat();
            cv.filter2D(gray, filtered, cv.CV_8UC1, kernel);

            binary = new cv.Mat();
            cv.threshold(filtered, binary, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU);

            contours = new cv.MatVector();
            hierarchy = new cv.Mat();
            cv.findContours(binary, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

            const textRegions = groupTextRegions(contours, img);

            for (const region of textRegions) {
              const aspectRatio = region.width / region.height;
              const imageArea = img.naturalWidth * img.naturalHeight;
              const relativeArea = (region.width * region.height) / imageArea;

              if (relativeArea > 0.0008 && relativeArea < 0.03 &&
                  aspectRatio > 2.5 && aspectRatio < 6.5 &&
                  region.width > 40 && region.height > 10) {

                const textScore = await validateTextCharacteristics(src, region);

                if (textScore > 0.5) {
                  candidates.push({
                    x: region.x,
                    y: region.y,
                    width: region.width,
                    height: region.height,
                    confidence: textScore * 0.8,
                    method: `texture_${orientation}_${frequency}`,
                    angle: 0,
                    textScore,
                    geometryScore: textScore
                  });
                  console.log(`      Texture candidate found: [${region.x}, ${region.y}, ${region.width}, ${region.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Confidence: ${textScore.toFixed(2)}`);
                }
              }
            }
          } catch (innerErr) {
            console.warn(`Inner texture analysis error for orientation ${orientation}, frequency ${frequency}:`, innerErr);
          } finally {
            kernel?.delete && kernel.delete();
            filtered?.delete && filtered.delete();
            binary?.delete && binary.delete();
            contours?.delete && contours.delete();
            hierarchy?.delete && hierarchy.delete();
          }
        }
      }
    } catch (err) {
      console.error('Texture analysis error:', err);
    } finally {
      src?.delete && src.delete();
      gray?.delete && gray.delete();
    }
    
    return candidates;
  };

  // Stage 4: Gradient-based Edge Enhancement
  const performGradientAnalysis = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üìê Stage 4: Gradient-based Edge Enhancement');
    let src: any, gray: any;
    const candidates: PlateDetection[] = [];
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      // Compute gradients in X and Y directions
      const gradX = new cv.Mat();
      const gradY = new cv.Mat();
      const absGradX = new cv.Mat();
      const absGradY = new cv.Mat();
      const grad = new cv.Mat();
      
      // Sobel operators for gradient computation
      cv.Sobel(gray, gradX, cv.CV_16S, 1, 0, 3);
      cv.Sobel(gray, gradY, cv.CV_16S, 0, 1, 3);
      
      // Convert to absolute values and combine
      cv.convertScaleAbs(gradX, absGradX);
      cv.convertScaleAbs(absGradY, absGradY);
      cv.addWeighted(absGradX, 0.5, absGradY, 0.5, 0, grad);
      
      // Apply threshold to create binary image
      const binary = new cv.Mat();
      cv.threshold(grad, binary, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU);
      
      // Morphological operations to connect text components
      const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3));
      cv.morphologyEx(binary, binary, cv.MORPH_CLOSE, kernel);
      
      // Find contours
      const contours = new cv.MatVector();
      const hierarchy = new cv.Mat();
      cv.findContours(binary, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      console.log(`  Found ${contours.size()} contours for gradient analysis.`);

      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const area = cv.contourArea(contour);
        const rect = cv.boundingRect(contour);
        
        const aspectRatio = rect.width / rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;
        
        if (relativeArea > 0.0008 && relativeArea < 0.025 &&
            aspectRatio > 2.8 && aspectRatio < 6.2 &&
            rect.width > 45 && rect.height > 12) {
          
          // Analyze gradient strength within the region
          const gradientStrength = await analyzeGradientStrength(grad, rect);
          
          if (gradientStrength > 0.6) {
            candidates.push({
              x: rect.x,
              y: rect.y,
              width: rect.width,
              height: rect.height,
              confidence: gradientStrength * 0.85,
              method: 'gradient',
              angle: 0,
              textScore: gradientStrength,
              geometryScore: gradientStrength
            });
            console.log(`      Gradient candidate found: [${rect.x}, ${rect.y}, ${rect.width}, ${rect.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Confidence: ${gradientStrength.toFixed(2)}`);
          }
        }
        
        contour.delete();
      }
      
      // Cleanup
      gradX.delete();
      gradY.delete();
      absGradX.delete();
      absGradY.delete();
      grad.delete();
      binary.delete();
      kernel.delete();
      contours.delete();
      hierarchy.delete();
      
    } catch (err) {
      console.error('Gradient analysis error:', err);
    } finally {
      try {
        src?.delete && src.delete();
        gray?.delete && gray.delete();
      } catch (cleanupErr) {
        console.warn('Cleanup error in gradient analysis:', cleanupErr);
      }
    }
    
    return candidates;
  };

  // Stage 5: Advanced Fusion and Validation System
  const performIntelligentFusion = async (candidates: PlateDetection[], img: HTMLImageElement): Promise<PlateDetection[]> => {
    console.log(`üß† Stage 5: Intelligent Fusion of ${candidates.length} candidates`);
    
    if (candidates.length === 0) return [];
    
    // Group overlapping candidates
    const groups = groupOverlappingCandidates(candidates);
    const finalDetections: PlateDetection[] = [];
    
    for (const group of groups) {
      if (group.length === 1) {
        // Single candidate - validate thoroughly
        const candidate = group[0];
        const finalScore = await performFinalValidation(candidate, img);
        
        if (finalScore > 0.85) {  // Much stricter threshold
          finalDetections.push({
            ...candidate,
            confidence: finalScore
          });
          console.log(`    Single candidate passed final validation: [${candidate.x}, ${candidate.y}, ${candidate.width}, ${candidate.height}], Final Score: ${finalScore.toFixed(2)}`);
        } else {
          console.log(`    Single candidate failed final validation: [${candidate.x}, ${candidate.y}, ${candidate.width}, ${candidate.height}], Final Score: ${finalScore.toFixed(2)}`);
        }
      } else {
        // Multiple overlapping candidates - use ensemble scoring
        const fusedCandidate = await fuseMultipleCandidates(group, img);
        
        if (fusedCandidate && fusedCandidate.confidence > 0.9) {  // Much stricter
          finalDetections.push(fusedCandidate);
          console.log(`    Fused candidate passed final validation: [${fusedCandidate.x}, ${fusedCandidate.y}, ${fusedCandidate.width}, ${fusedCandidate.height}], Confidence: ${fusedCandidate.confidence.toFixed(2)}`);
        } else if (fusedCandidate) {
          console.log(`    Fused candidate failed final validation: [${fusedCandidate.x}, ${fusedCandidate.y}, ${fusedCandidate.width}, ${fusedCandidate.height}], Confidence: ${fusedCandidate.confidence.toFixed(2)}`);
        }
      }
    }
    
    // Sort by confidence and return multiple high-confidence detections
    finalDetections.sort((a, b) => b.confidence - a.confidence);
    // Return up to 5 plates if confidence >= 90% (or 60% in debug mode)
    const minConfidence = debugMode ? 0.6 : 0.9;
    const maxResults = debugMode ? 10 : 5;
    const filteredFinalDetections = finalDetections.filter(d => d.confidence >= minConfidence).slice(0, maxResults);
    console.log(`üß† Final Intelligent Fusion resulted in ${filteredFinalDetections.length} detections (min confidence: ${minConfidence}).`);
    return filteredFinalDetections;
  };

  // Advanced geometric metrics calculation (Improved)
  const calculateGeometricMetrics = (
    rect: any,
    aspectRatio: number,
    area: number,
    img: HTMLImageElement,
    angle: number,
    contour: any // Pass the contour directly
  ): DetectionMetrics => {
    const imageArea = img.naturalWidth * img.naturalHeight;
    const relativeArea = area / imageArea;
    
    // Aspect ratio score (optimal range for AU plates: ~2.78 to ~3.7 for standard, wider for others)
    const idealAspectRatio = 3.0; // A general ideal for many plates
    let aspectRatioScore = aspectRatio >= 2.0 && aspectRatio <= 7.0 
      ? 1.0 - Math.abs(aspectRatio - idealAspectRatio) / (idealAspectRatio * 2) 
      : 0; // Broader range, penalize deviation
    aspectRatioScore = Math.max(0, aspectRatioScore); // Ensure non-negative

    // Size score (optimal relative area: 0.003-0.02)
    const idealRelativeArea = 0.008;
    let sizeScore = relativeArea >= 0.0005 && relativeArea <= 0.05
      ? 1.0 - Math.abs(relativeArea - idealRelativeArea) / (idealRelativeArea * 2)
      : 0; // Broader range, penalize deviation
    sizeScore = Math.max(0, sizeScore); // Ensure non-negative

    // Position score (license plates can be anywhere in the image)
    const verticalPosition = (rect.y + rect.height / 2) / img.naturalHeight;
    const positionScore = verticalPosition >= 0.05 && verticalPosition <= 0.95 ? 0.8 : 0.3; // Allow plates anywhere except extreme edges
    
    // Angle score (prefer minimal rotation)
    const angleScore = angle <= 25 ? 1.0 - (angle / 25) : 0.1; // Allow more tilt for real-world images
    
    // Compactness score (license plates should be reasonably compact)
    const perimeter = cv.arcLength(contour, true);
    const compactness = (4 * Math.PI * area) / (perimeter * perimeter);
    const compactnessScore = compactness > 0.2 ? Math.min(compactness * 1.5, 1.0) : 0; // Boost for good compactness
    
    // Rectangularity score (should be close to rectangular)
    const rectangularity = area / (rect.width * rect.height);
    const rectangularityScore = rectangularity > 0.6 ? rectangularity : 0; // Penalize non-rectangular shapes
    
    // Calculate convexity
    const convexHull = new cv.Mat();
    cv.convexHull(contour, convexHull);
    const convexArea = cv.contourArea(convexHull);
    const solidity = area / convexArea;
    const solidityScore = solidity > 0.7 ? solidity : 0; // Penalize non-solid shapes
    convexHull.delete();

    // Overall geometry score - weighted sum of all metrics
    const geometryScore = (
      aspectRatioScore * 0.20 +
      sizeScore * 0.15 +
      positionScore * 0.10 +
      angleScore * 0.10 +
      compactnessScore * 0.20 +
      rectangularityScore * 0.15 +
      solidityScore * 0.10      // New metric
    );
    
    console.log(`    Geometric Metrics for [${rect.x}, ${rect.y}, ${rect.width}, ${rect.height}]:`);
    console.log(`      Aspect Ratio: ${aspectRatio.toFixed(2)} (Score: ${aspectRatioScore.toFixed(2)})`);
    console.log(`      Relative Area: ${relativeArea.toFixed(4)} (Score: ${sizeScore.toFixed(2)})`);
    console.log(`      Vertical Position: ${verticalPosition.toFixed(2)} (Score: ${positionScore.toFixed(2)})`);
    console.log(`      Angle: ${angle.toFixed(2)} (Score: ${angleScore.toFixed(2)})`);
    console.log(`      Compactness: ${compactness.toFixed(2)} (Score: ${compactnessScore.toFixed(2)})`);
    console.log(`      Rectangularity: ${rectangularity.toFixed(2)} (Score: ${rectangularityScore.toFixed(2)})`);
    console.log(`      Solidity: ${solidity.toFixed(2)} (Score: ${solidityScore.toFixed(2)})`);
    console.log(`      Overall Geometry Score: ${geometryScore.toFixed(2)}`);

    return {
      edgeQuality: compactnessScore, // Using compactness as edge quality proxy
      colorConsistency: 0, // Not calculated here
      textureComplexity: 0, // Not calculated here
      rectangularity: rectangularityScore,
      aspectRatioScore,
      positionScore,
      geometryScore
    };
  };

  // Helper Functions for Ultimate Detection System
  
  // Validate color consistency within a region (Improved for Australian Plates)
  const validateColorConsistency = async (src: any, rect: any, colorType: string): Promise<number> => {
    if (typeof cv === 'undefined') return 0;
    
    let roi: any, hsv: any, lab: any, channels: any;
    try {
      roi = src.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
      hsv = new cv.Mat();
      lab = new cv.Mat();
      channels = new cv.MatVector();
      
      cv.cvtColor(roi, hsv, cv.COLOR_RGB2HSV);
      cv.cvtColor(roi, lab, cv.COLOR_RGB2Lab);
      cv.split(hsv, channels);
      
      const sChannel = channels.get(1);
      const vChannel = channels.get(2);
      
      const sMean = new cv.Mat();
      const sStd = new cv.Mat();
      const vMean = new cv.Mat();
      const vStd = new cv.Mat();
      
      cv.meanStdDev(sChannel, sMean, sStd);
      cv.meanStdDev(vChannel, vMean, vStd);
      
      const saturationStd = sStd.data64F[0];
      const valueStd = vStd.data64F[0];
      const valueMean = vMean.data64F[0];

      let consistency = 0;

      switch (colorType) {
        case 'white':
          consistency = (valueMean > 180 ? 0.4 : 0) + 
                        (saturationStd < 20 ? 0.3 : 0) + 
                        (valueStd < 30 ? 0.3 : 0);
          break;
        case 'yellow':
          consistency = (valueMean > 150 ? 0.3 : 0) + 
                        (saturationStd < 40 ? 0.35 : 0) + 
                        (valueStd < 35 ? 0.35 : 0);
          break;
        case 'australian_green_white':
          // Specific checks for green text on white background
          // Analyze green channel in HSV or LAB for text color
          // Analyze lightness in LAB for background color
          consistency = (valueMean > 150 && valueMean < 250 ? 0.4 : 0) + 
                        (saturationStd < 30 ? 0.3 : 0) + 
                        (valueStd < 40 ? 0.3 : 0);
          break;
        case 'australian_black_white':
          // Specific checks for black text on white background
          consistency = (valueMean > 150 && valueMean < 250 ? 0.4 : 0) + 
                        (saturationStd < 30 ? 0.3 : 0) + 
                        (valueStd < 40 ? 0.3 : 0);
          break;
        case 'australian_white_black':
          // Specific checks for white text on black background
          consistency = (valueMean > 0 && valueMean < 100 ? 0.4 : 0) + 
                        (saturationStd < 30 ? 0.3 : 0) + 
                        (valueStd < 40 ? 0.3 : 0);
          break;
        case 'australian_red_white':
          // Specific checks for red text on white background
          consistency = (valueMean > 150 && valueMean < 250 ? 0.4 : 0) + 
                        (saturationStd < 30 ? 0.3 : 0) + 
                        (valueStd < 40 ? 0.3 : 0);
          break;
        default:
          consistency = Math.max(0, 1 - (saturationStd + valueStd) / 100);
          break;
      }
      
      console.log(`    Color consistency for ${colorType}: Saturation Std: ${saturationStd.toFixed(2)}, Value Std: ${valueStd.toFixed(2)}, Value Mean: ${valueMean.toFixed(2)}, Consistency: ${consistency.toFixed(2)}`);

      return Math.min(consistency, 1.0);
      
    } catch (err) {
      console.warn('Color consistency validation error:', err);
      return 0;
    } finally {
      roi?.delete();
      hsv?.delete();
      lab?.delete();
      channels?.delete();
    }
  };

  // Detect text presence using advanced pattern analysis (Improved)
  const detectTextPresence = async (src: any, rect: any): Promise<number> => {
    if (typeof cv === 'undefined') return 0;
    
    let roi: any, gray: any, binary: any, contours: any, hierarchy: any;
    try {
      roi = src.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
      gray = new cv.Mat();
      binary = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(roi, gray, cv.COLOR_RGB2GRAY);
      
      // Multiple binarization techniques for better text extraction
      const adaptiveBinary = new cv.Mat();
      const otsuBinary = new cv.Mat();
      
      cv.adaptiveThreshold(gray, adaptiveBinary, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 11, 2);
      cv.threshold(gray, otsuBinary, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU);
      
      // Combine both methods to get a robust binary image
      cv.bitwise_and(adaptiveBinary, otsuBinary, binary);
      
      // Morphological operations to connect broken characters
      const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(3, 3));
      cv.morphologyEx(binary, binary, cv.MORPH_CLOSE, kernel);

      cv.findContours(binary, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      let characterLikeShapes = 0;
      let totalArea = 0;
      const roiArea = rect.width * rect.height;
      
      console.log(`    Text presence analysis for region [${rect.x}, ${rect.y}, ${rect.width}, ${rect.height}]: Found ${contours.size()} contours.`);

      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const area = cv.contourArea(contour);
        const contourRect = cv.boundingRect(contour);
        
        const aspectRatio = contourRect.width / contourRect.height;
        const relativeArea = area / roiArea;
        
        // Character-like criteria (adjusted for typical Australian plate characters)
        if (relativeArea > 0.005 && relativeArea < 0.3 && // Broader relative area for characters
            aspectRatio > 0.05 && aspectRatio < 5.0 && // Broader aspect ratio for characters
            contourRect.height > rect.height * 0.15 && // Minimum character height
            contourRect.width > rect.width * 0.02) { // Minimum character width
          
          characterLikeShapes++;
          totalArea += area;
          console.log(`      Character-like shape found: [${contourRect.x}, ${contourRect.y}, ${contourRect.width}, ${contourRect.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Relative Area: ${relativeArea.toFixed(4)}`);
        }
        
        contour.delete();
      }
      
      // Calculate text presence score
      const characterCount = characterLikeShapes;
      const areaRatio = totalArea / roiArea;
      
      let textScore = 0;
      
      // License plates typically have 4-8 characters (adjusted for AU plates)
      if (characterCount >= 3 && characterCount <= 9) { // AU plates can have 3-8 chars
        textScore += 0.5;
      }
      
      // Text should occupy 15-40% of the plate area
      if (areaRatio > 0.1 && areaRatio < 0.5) { // Broader range for text area
        textScore += 0.3;
      }
      
      // Bonus for optimal character count
      if (characterCount >= 5 && characterCount <= 8) {
        textScore += 0.2;
      }
      
      console.log(`    Text presence score: Character Count: ${characterCount}, Area Ratio: ${areaRatio.toFixed(4)}, Final Score: ${textScore.toFixed(2)}`);

      // Cleanup
      adaptiveBinary.delete();
      otsuBinary.delete();
      
      return Math.min(textScore, 1.0);
      
    } catch (err) {
      console.warn('Text presence detection error:', err);
      return 0;
    } finally {
      roi?.delete();
      gray?.delete();
      binary?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
  };

  // Validate text characteristics with advanced analysis
  const validateTextCharacteristics = async (src: any, rect: any): Promise<number> => {
    return await detectTextPresence(src, rect);
  };

  // üî• AGGRESSIVE DETECTION - ‰∏∫Èöæ‰ª•Ê£ÄÊµãÁöÑÂõæÁâáËÆæËÆ°
  const performAggressiveDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üî• AGGRESSIVE: Very loose detection for difficult images');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, edges: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      edges = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      // Â§öÁßçËæπÁºòÊ£ÄÊµãÊñπÊ≥ï
      const edgeMethods = [
        { blur: 3, low: 30, high: 100 }, // ÂæàÊïèÊÑü
        { blur: 5, low: 20, high: 80 },  // Êõ¥ÊïèÊÑü
        { blur: 7, low: 15, high: 60 },  // ÊûÅÂÖ∂ÊïèÊÑü
      ];
      
      for (const method of edgeMethods) {
        // È´òÊñØÊ®°Á≥ä
        const blurred = new cv.Mat();
        cv.GaussianBlur(gray, blurred, new cv.Size(method.blur, method.blur), 0);
        
        // Canny edge detection with adaptive thresholds
        const currentEdges = new cv.Mat();
        cv.Canny(blurred, currentEdges, method.low, method.high);
        
        // Â§öÁßçÂΩ¢ÊÄÅÂ≠¶Êìç‰Ωú
        const kernels = [
          cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(15, 3)),
          cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(25, 5)),
          cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(30, 6)),
        ];
        
        for (const kernel of kernels) {
          const morphed = new cv.Mat();
          cv.morphologyEx(currentEdges, morphed, cv.MORPH_CLOSE, kernel);
          
          // Êü•ÊâæËΩÆÂªì
          const currentContours = new cv.MatVector();
          const currentHierarchy = new cv.Mat();
          cv.findContours(morphed, currentContours, currentHierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
          
          // ÈùûÂ∏∏ÂÆΩÊùæÁöÑÊù°‰ª∂
          for (let i = 0; i < currentContours.size(); i++) {
            const contour = currentContours.get(i);
            const area = cv.contourArea(contour);
            const rect = cv.boundingRect(contour);
            
            const aspectRatio = rect.width / rect.height;
            const imageArea = img.naturalWidth * img.naturalHeight;
            const relativeArea = area / imageArea;
            
            // ÊøÄËøõÁöÑÂÆΩÊùæÊù°‰ª∂
            if (aspectRatio >= 1.5 && aspectRatio <= 8.0 && 
                relativeArea >= 0.0005 && relativeArea <= 0.1 &&
                rect.width >= 40 && rect.height >= 12 &&
                rect.width <= 800 && rect.height <= 300) {
              
              let confidence = 0.4; // ËæÉ‰ΩéÂü∫Á°Ä‰ø°ÂøÉÂ∫¶
              
              // ÁÆÄÂçïËØÑÂàÜ
              if (aspectRatio >= 2.0 && aspectRatio <= 6.0) confidence += 0.2;
              if (relativeArea >= 0.001 && relativeArea <= 0.05) confidence += 0.1;
              if (rect.y >= img.naturalHeight * 0.02) confidence += 0.1;
              
              detections.push({
                x: rect.x,
                y: rect.y,
                width: rect.width,
                height: rect.height,
                confidence: confidence,
                method: `aggressive-${method.blur}-${method.low}`,
                angle: 0,
                textScore: 0.5,
                geometryScore: confidence
              });
            }
            
            contour.delete();
          }
          
          currentContours.delete();
          currentHierarchy.delete();
          morphed.delete();
          kernel.delete();
        }
        
        currentEdges.delete();
        blurred.delete();
      }
      
      debugMode && console.log(`Aggressive detection found ${detections.length} raw candidates`);
      
    } catch (err) {
      console.error('Aggressive detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      edges?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    // ËøîÂõûÊâÄÊúâÂÄôÈÄâÔºå‰ø°ÂøÉÂ∫¶ÊéíÂ∫èÔºåÊúÄÂ§ö10‰∏™
    return detections
      .sort((a, b) => b.confidence - a.confidence)
      .slice(0, 10);
  };

  // üí™ ROBUST MULTI-METHOD DETECTION - Â§öÊñπÊ≥ïÁªÑÂêàÊ£ÄÊµã
  const performRobustMultiMethodDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üí™ ROBUST: Multi-method combined detection');
    let allDetections: PlateDetection[] = [];
    
    try {
      // ÊñπÊ≥ï1ÔºöÂéüÊúâÁöÑÁÆÄÂçïÊúâÊïàÊ£ÄÊµã
      const simpleResults = await performSimpleEffectiveDetection(img, canvas);
      allDetections = [...allDetections, ...simpleResults];
      debugMode && console.log(`Simple method: ${simpleResults.length} detections`);
      
      // ÊñπÊ≥ï2ÔºöÊæ≥Ê¥≤ÁâπÂåñÊ£ÄÊµã
      const australianResults = await performAustralianPlateDetection(img, canvas, []); // No ground truth for robust
      allDetections = [...allDetections, ...australianResults];
      debugMode && console.log(`Australian method: ${australianResults.length} detections`);
      
      // ÊñπÊ≥ï3ÔºöÂ§öÂ∞∫Â∫¶Ê£ÄÊµã
      const multiscaleResults = await performMultiScaleDetection(img, canvas);
      allDetections = [...allDetections, ...multiscaleResults];
      debugMode && console.log(`Multi-scale method: ${multiscaleResults.length} detections`);
      
      // ÊñπÊ≥ï4ÔºöÈ¢úËâ≤Âü∫Á°ÄÊ£ÄÊµã
      const colorResults = await performColorBasedDetection(img, canvas);
      allDetections = [...allDetections, ...colorResults];
      debugMode && console.log(`Color-based method: ${colorResults.length} detections`);
      
      // ÂêàÂπ∂ÂíåËøáÊª§ÁªìÊûú
      const combinedResults = combineAndFilterDetections(allDetections);
      debugMode && console.log(`Combined and filtered: ${combinedResults.length} final detections`);
      
      return combinedResults;
      
    } catch (err) {
      console.error('Robust detection error:', err);
      return [];
    }
  };

  // üîÑ MULTIPLE FALLBACK METHODS - Â§öÁßçfallbackÊñπÊ≥ï
  const performMultipleFallbackMethods = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    console.log('üîÑ Trying multiple fallback methods...');
    let allResults: PlateDetection[] = [];
    
    try {
      // Fallback 1: ÊûÅÂÖ∂ÂÆΩÊùæÁöÑÂü∫Á°ÄÊ£ÄÊµã
      const basic = await performBasicRectangleDetection(img, canvas);
      allResults = [...allResults, ...basic];
      
      // Fallback 2: ËΩÆÂªìÈù¢ÁßØÊ£ÄÊµã
      const contour = await performContourAreaDetection(img, canvas);
      allResults = [...allResults, ...contour];
      
      // Fallback 3: ËæπÁºòÂØÜÂ∫¶Ê£ÄÊµã
      const edge = await performEdgeDensityDetection(img, canvas);
      allResults = [...allResults, ...edge];
      
      debugMode && console.log(`Fallback methods found ${allResults.length} total candidates`);
      
      // Â¶ÇÊûúËøòÊòØÊ≤°ÊúâÁªìÊûúÔºåÂ∞ùËØïÈùûÂ∏∏ÊøÄËøõÁöÑÊ£ÄÊµã
      if (allResults.length === 0) {
        console.log('üö® No results from fallback, trying ultra-aggressive...');
        const ultra = await performUltraAggressiveDetection(img, canvas);
        allResults = [...allResults, ...ultra];
      }
      
      return allResults.slice(0, 5); // ÊúÄÂ§öËøîÂõû5‰∏™
      
    } catch (err) {
      console.error('Fallback methods error:', err);
      return [];
    }
  };

  // WATERMARKLY-STYLE SIMPLE & EFFECTIVE DETECTION (2025) - ÂÉèWatermarkly‰∏ÄÊ†∑ÂáÜÁ°Æ
  const performSimpleEffectiveDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üöÄ WATERMARKLY-STYLE: Simple but highly effective detection');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, edges: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      edges = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      // WatermarklyÂºèÁÆÄÂçï‰ΩÜÊúâÊïàÁöÑËæπÁºòÊ£ÄÊµã
      cv.GaussianBlur(gray, gray, new cv.Size(5, 5), 0);
      cv.Canny(gray, edges, 50, 200);
      
      // ÂΩ¢ÊÄÅÂ≠¶Êìç‰Ωú - ËøûÊé•Â≠óÁ¨¶
      const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(20, 4));
      cv.morphologyEx(edges, edges, cv.MORPH_CLOSE, kernel);
      
      // Êü•ÊâæËΩÆÂªì
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      // ÂàÜÊûêËΩÆÂªì - ‰ΩøÁî®WatermarklyÂºèÁöÑÁÆÄÂçï‰ΩÜ‰∏•Ê†ºÊ†áÂáÜ
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const area = cv.contourArea(contour);
        const rect = cv.boundingRect(contour);
        
        // ËÆ°ÁÆóÂü∫Êú¨ÊåáÊ†á
        const aspectRatio = rect.width / rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;
        
        // WATERMARKLYÂºè‰∏•Ê†ºÊù°‰ª∂Ôºö‰∏ìÊ≥®‰∫éÁúüÊ≠£ÁöÑËΩ¶ÁâåÁâπÂæÅ
        const isPlateAspectRatio = aspectRatio >= 2.0 && aspectRatio <= 6.0; // ËΩ¶ÁâåÂÆΩÈ´òÊØî
        const isReasonableSize = relativeArea >= 0.0015 && relativeArea <= 0.03; // ÂêàÁêÜÂ§ßÂ∞è
        const isMinimumDimensions = rect.width >= 80 && rect.height >= 20; // ÊúÄÂ∞èÂèØËØªÂ∞∫ÂØ∏
        const isMaximumDimensions = rect.width <= 500 && rect.height <= 200; // ÊúÄÂ§ßÂêàÁêÜÂ∞∫ÂØ∏
        const isNotAtTop = rect.y >= img.naturalHeight * 0.02; // ‰∏çÂú®ÂõæÁâáÊûÅÈ°∂ÈÉ®
        const isNotAtBottom = rect.y <= img.naturalHeight * 0.98; // ‰∏çÂú®ÂõæÁâáÊûÅÂ∫ïÈÉ®
        
        // È¢ùÂ§ñÈ™åËØÅÔºöËæπÁºòË¥®ÈáèÊ£ÄÊü•
        const edgeQuality = await checkEdgeQuality(src, rect);
        const colorUniformity = await checkColorUniformity(src, rect);
        
        if (isPlateAspectRatio && isReasonableSize && isMinimumDimensions && 
            isMaximumDimensions && isNotAtTop && isNotAtBottom &&
            edgeQuality > 0.6 && colorUniformity > 0.5) {
          
          // ËÆ°ÁÆóconfidence - WatermarklyÂºèËØÑÂàÜ
          let confidence = 0.6; // Âü∫Á°Ä‰ø°ÂøÉÂ∫¶
          
          // ÂÆΩÈ´òÊØîËØÑÂàÜ (Êé•ËøëÊæ≥Ê¥≤ËΩ¶ÁâåÊ†áÂáÜ2.78Êõ¥Â•Ω)
          const idealRatio = 2.78;
          const ratioScore = 1.0 - Math.abs(aspectRatio - idealRatio) / idealRatio;
          confidence += ratioScore * 0.2;
          
          // Â∞∫ÂØ∏ËØÑÂàÜ
          const idealRelativeArea = 0.008;
          const sizeScore = 1.0 - Math.abs(relativeArea - idealRelativeArea) / idealRelativeArea;
          confidence += Math.max(0, Math.min(sizeScore, 0.2));
          
          // ‰ΩçÁΩÆËØÑÂàÜ (‰ªª‰Ωï‰ΩçÁΩÆÈÉΩÂèØÊé•Âèó)
          const verticalPos = (rect.y + rect.height / 2) / img.naturalHeight;
          const positionScore = verticalPos >= 0.05 && verticalPos <= 0.95 ? 0.1 : 0;
          confidence += positionScore;
          
          // ËæπÁºòÂíåÈ¢úËâ≤Ë¥®ÈáèÂ•ñÂä±
          confidence += edgeQuality * 0.1;
          confidence += colorUniformity * 0.1;
          
          // Âè™Êé•ÂèóÈ´ò‰ø°ÂøÉÂ∫¶Ê£ÄÊµã (ÂÉèWatermarkly‰∏ÄÊ†∑‰∏•Ê†º)
          if (confidence >= 0.85) {
            detections.push({
              x: rect.x,
              y: rect.y,
              width: rect.width,
              height: rect.height,
              confidence: Math.min(confidence, 0.98), // ÈôêÂà∂ÊúÄÈ´ò98%
              method: 'watermarkly-style-simple',
              angle: 0,
              textScore: edgeQuality,
              geometryScore: ratioScore
            });
          }
        }
        
        contour.delete();
      }
      
      // ÁßªÈô§ÈáçÂè†Ê£ÄÊµã
      const filteredDetections = removeOverlappingDetections(detections);
      console.log(`Watermarkly-style detection: ${filteredDetections.length} final plates`);
      
    } catch (err) {
      console.error('Watermarkly-style detection error:', err);
    } finally {
      // Ê∏ÖÁêÜ
      src?.delete();
      gray?.delete();
      edges?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections.slice(0, 3); // Return top 3 high-confidence detections
  };

  // ÁÆÄÂçïÊúâÊïàÁöÑËæπÁºòË¥®ÈáèÊ£ÄÊü•
  const checkEdgeQuality = async (src: any, rect: any): Promise<number> => {
    if (typeof cv === 'undefined') return 0;
    
    try {
      const roi = src.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
      const gray = new cv.Mat();
      const edges = new cv.Mat();
      
      cv.cvtColor(roi, gray, cv.COLOR_RGB2GRAY);
      cv.Canny(gray, edges, 50, 150);
      
      // ËÆ°ÁÆóËæπÁºòÂØÜÂ∫¶
      const edgePixels = cv.countNonZero(edges);
      const totalPixels = edges.rows * edges.cols;
      const edgeDensity = edgePixels / totalPixels;
      
      // ËΩ¶ÁâåÂ∫îËØ•ÊúâÈÄÇÂ∫¶ÁöÑËæπÁºòÂØÜÂ∫¶ (0.1-0.4)
      const qualityScore = edgeDensity >= 0.1 && edgeDensity <= 0.4 ? 
        Math.min(edgeDensity * 2.5, 1.0) : 0.3;
      
      roi.delete();
      gray.delete();
      edges.delete();
      
      return qualityScore;
    } catch (err) {
      return 0.5; // ÈªòËÆ§‰∏≠Á≠âË¥®Èáè
    }
  };

  // ÁÆÄÂçïÊúâÊïàÁöÑÈ¢úËâ≤ÂùáÂåÄÊÄßÊ£ÄÊü•
  const checkColorUniformity = async (src: any, rect: any): Promise<number> => {
    if (typeof cv === 'undefined') return 0;
    
    try {
      const roi = src.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
      const gray = new cv.Mat();
      
      cv.cvtColor(roi, gray, cv.COLOR_RGB2GRAY);
      
      // ËÆ°ÁÆóÊ†áÂáÜÂ∑Æ
      const mean = new cv.Mat();
      const stddev = new cv.Mat();
      cv.meanStdDev(gray, mean, stddev);
      
      const standardDeviation = stddev.data64F[0];
      
      // ËΩ¶ÁâåÂ∫îËØ•Êúâ‰∏≠Á≠âÁöÑÊ†áÂáÜÂ∑Æ (20-80)
      const uniformityScore = standardDeviation >= 20 && standardDeviation <= 80 ? 
        1.0 - Math.abs(standardDeviation - 50) / 50 : 0.3;
      
      roi.delete();
      gray.delete();
      mean.delete();
      stddev.delete();
      
      return Math.max(uniformityScore, 0.3);
    } catch (err) {
      return 0.5; // ÈªòËÆ§‰∏≠Á≠âË¥®Èáè
    }
  };

  // ÁßªÈô§ÈáçÂè†Ê£ÄÊµã
  const removeOverlappingDetections = (detections: PlateDetection[]): PlateDetection[] => {
    const filtered: PlateDetection[] = [];
    
    for (const detection of detections) {
      let isOverlapping = false;
      
      for (const existing of filtered) {
        const overlapArea = calculateOverlapArea(detection, existing);
        const minArea = Math.min(
          detection.width * detection.height,
          existing.width * existing.height
        );
        const overlapRatio = overlapArea / minArea;
        
        if (overlapRatio > 0.3) { // 30%ÈáçÂè†ËÆ§‰∏∫ÊòØÂêå‰∏Ä‰∏™
          isOverlapping = true;
          break;
        }
      }
      
      if (!isOverlapping) {
        filtered.push(detection);
      }
    }
    
    return filtered;
  };

  // ËÆ°ÁÆóÈáçÂè†Èù¢ÁßØ
  const calculateOverlapArea = (a: PlateDetection, b: PlateDetection): number => {
    const left = Math.max(a.x, b.x);
    const right = Math.min(a.x + a.width, b.x + b.width);
    const top = Math.max(a.y, b.y);
    const bottom = Math.min(a.y + a.height, b.y + b.height);
    
    if (left < right && top < bottom) {
      return (right - left) * (bottom - top);
    }
    return 0;
  };

  // Â§öÂ∞∫Â∫¶Ê£ÄÊµã
  const performMultiScaleDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üîç Multi-Scale Detection (Improved)');
    const detections: PlateDetection[] = [];
    let src: any = null, gray: any = null, resized: any = null, edges: any = null, contours: any = null, hierarchy: any = null;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      
      // Multiple scales for robust detection
      const scales = [0.4, 0.6, 0.8, 1.0, 1.2, 1.4]; // Broader range of scales
      
      for (const scale of scales) {
        console.log(`  Processing at scale: ${scale.toFixed(2)}`);
        const resized = new cv.Mat();
        const newSize = new cv.Size(Math.round(gray.cols * scale), Math.round(gray.rows * scale));
        cv.resize(gray, resized, newSize, 0, 0, cv.INTER_AREA);
        
        const edges = new cv.Mat();
        cv.Canny(resized, edges, 30, 100); // Adjusted Canny thresholds
        
        // Morphological operations to connect edges
        const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(18, 3)); // Adjusted kernel size
        cv.morphologyEx(edges, edges, cv.MORPH_CLOSE, kernel);

        const contours = new cv.MatVector();
        const hierarchy = new cv.Mat();
        cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
        
        console.log(`    Found ${contours.size()} contours at scale ${scale.toFixed(2)}.`);

        for (let i = 0; i < contours.size(); i++) {
          const contour = contours.get(i);
          const rect = cv.boundingRect(contour);
          
          // Scale back to original image coordinates
          const scaledRect = {
            x: Math.round(rect.x / scale),
            y: Math.round(rect.y / scale),
            width: Math.round(rect.width / scale),
            height: Math.round(rect.height / scale)
          };
          
          const aspectRatio = scaledRect.width / scaledRect.height;
          
          // Filter based on aspect ratio and size (adjusted for AU plates)
          if (aspectRatio >= 2.0 && aspectRatio <= 7.0 && // Broader aspect ratio
              scaledRect.width >= 40 && scaledRect.height >= 10 && // Smaller minimum dimensions
              scaledRect.width <= img.naturalWidth * 0.8 && scaledRect.height <= img.naturalHeight * 0.4) { // Max dimensions
            
            // Calculate a basic confidence score for multi-scale detection
            let confidence = 0.6; 
            if (aspectRatio > 2.5 && aspectRatio < 4.0) confidence += 0.1; // Reward common AU aspect ratios
            if (scaledRect.width > 80 && scaledRect.height > 20) confidence += 0.1; // Reward larger, clearer plates

            detections.push({
              x: scaledRect.x,
              y: scaledRect.y,
              width: scaledRect.width,
              height: scaledRect.height,
              confidence: Math.min(confidence, 0.9), // Cap confidence
              method: `multiscale-${scale.toFixed(2)}`,
              angle: 0,
              textScore: 0.5,
              geometryScore: 0.6
            });
            console.log(`      Multi-scale candidate found: [${scaledRect.x}, ${scaledRect.y}, ${scaledRect.width}, ${scaledRect.height}], Aspect Ratio: ${aspectRatio.toFixed(2)}, Confidence: ${confidence.toFixed(2)}`);
          }
          
          contour.delete();
        }
        
        contours.delete();
        hierarchy.delete();
        edges.delete();
        resized.delete();
      }
      
    } catch (err) {
      console.error('Multi-scale detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      resized?.delete();
      edges?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections.slice(0, 10); // Return top 10 candidates from multi-scale
  };

  // È¢úËâ≤Âü∫Á°ÄÊ£ÄÊµã
  const performColorBasedDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üåà Color-Based Detection');
    let src: any, hsv: any, mask: any, contours: any, hierarchy: any;
    const candidates: PlateDetection[] = [];
    
    try {
      src = cv.imread(img);
      hsv = new cv.Mat();
      mask = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, hsv, cv.COLOR_RGB2HSV);
      
      // Define a broader range for yellow/orange colors (common in some plates)
      const lowerYellow = new cv.Scalar(15, 100, 100);
      const upperYellow = new cv.Scalar(35, 255, 255);
      cv.inRange(hsv, lowerYellow, upperYellow, mask);
      
      // Morphological operations to clean up the mask
      const kernel = cv.getStructuringElement(cv.MORPH_RECT, new cv.Size(5, 5));
      cv.morphologyEx(mask, mask, cv.MORPH_OPEN, kernel);
      cv.morphologyEx(mask, mask, cv.MORPH_CLOSE, kernel);
      
      cv.findContours(mask, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const rect = cv.boundingRect(contour);
        const area = cv.contourArea(contour);
        
        const aspectRatio = rect.width / rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;

        if (aspectRatio >= 2.0 && aspectRatio <= 6.0 &&
            relativeArea >= 0.001 && relativeArea <= 0.05 &&
            rect.width >= 50 && rect.height >= 15) {
          
          candidates.push({
            x: rect.x,
            y: rect.y,
            width: rect.width,
            height: rect.height,
            confidence: 0.7, // Base confidence for color detection
            method: 'color-based',
            angle: 0,
            textScore: 0.5,
            geometryScore: 0.6
          });
        }
        contour.delete();
      }
      
      // Cleanup
      lowerYellow.delete();
      upperYellow.delete();
      kernel.delete();
      
    } catch (err) {
      console.error('Color-based detection error:', err);
    } finally {
      src?.delete();
      hsv?.delete();
      mask?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return candidates;
  };

  // ÊûÅÂÖ∂ÂÆΩÊùæÁöÑÂü∫Á°ÄÊ£ÄÊµã
  const performBasicRectangleDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üîç Basic Rectangle Detection (Very Loose)');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, edges: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      edges = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.Canny(gray, edges, 10, 50); // Very loose Canny thresholds
      
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const rect = cv.boundingRect(contour);
        
        const aspectRatio = rect.width / rect.height;
        const area = rect.width * rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;

        // Very loose criteria for rectangles
        if (aspectRatio >= 1.0 && aspectRatio <= 10.0 && // Very broad aspect ratio
            relativeArea >= 0.0001 && relativeArea <= 0.1 && // Very broad size
            rect.width >= 20 && rect.height >= 5) { // Very small minimum dimensions
          
          detections.push({
            x: rect.x,
            y: rect.y,
            width: rect.width,
            height: rect.height,
            confidence: 0.3, // Very low confidence
            method: 'basic-rectangle',
            angle: 0,
            textScore: 0.2,
            geometryScore: 0.3
          });
        }
        contour.delete();
      }
      
    } catch (err) {
      console.error('Basic rectangle detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      edges?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections;
  };

  // ËΩÆÂªìÈù¢ÁßØÊ£ÄÊµã
  const performContourAreaDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üìê Contour Area Detection');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, thresh: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      thresh = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.threshold(gray, thresh, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU);
      
      cv.findContours(thresh, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
      
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const area = cv.contourArea(contour);
        const rect = cv.boundingRect(contour);
        
        const aspectRatio = rect.width / rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;

        // Filter based on area and aspect ratio
        if (relativeArea > 0.0005 && relativeArea < 0.05 &&
            aspectRatio >= 1.5 && aspectRatio <= 7.0) {
          
          detections.push({
            x: rect.x,
            y: rect.y,
            width: rect.width,
            height: rect.height,
            confidence: 0.6, // Moderate confidence
            method: 'contour-area',
            angle: 0,
            textScore: 0.4,
            geometryScore: 0.5
          });
        }
        contour.delete();
      }
      
    } catch (err) {
      console.error('Contour area detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      thresh?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections;
  };

  // ËæπÁºòÂØÜÂ∫¶Ê£ÄÊµã
  const performEdgeDensityDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üìè Edge Density Detection');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, edges: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      edges = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.Canny(gray, edges, 50, 150);
      
      cv.findContours(edges, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
      
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const rect = cv.boundingRect(contour);
        
        const aspectRatio = rect.width / rect.height;
        const area = rect.width * rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;

        // Calculate edge density within the bounding box
        const roiEdges = edges.roi(new cv.Rect(rect.x, rect.y, rect.width, rect.height));
        const edgePixels = cv.countNonZero(roiEdges);
        const totalPixels = roiEdges.rows * roiEdges.cols;
        const edgeDensity = totalPixels > 0 ? edgePixels / totalPixels : 0;
        roiEdges.delete();

        // Filter based on aspect ratio, size, and edge density
        if (aspectRatio >= 2.0 && aspectRatio <= 6.0 &&
            relativeArea >= 0.001 && relativeArea <= 0.04 &&
            edgeDensity > 0.1 && edgeDensity < 0.5) { // Typical range for text-rich regions
          
          detections.push({
            x: rect.x,
            y: rect.y,
            width: rect.width,
            height: rect.height,
            confidence: 0.75, // Higher confidence for edge density
            method: 'edge-density',
            angle: 0,
            textScore: edgeDensity,
            geometryScore: 0.7
          });
        }
        contour.delete();
      }
      
    } catch (err) {
      console.error('Edge density detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      edges?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections;
  };

  // ÊûÅÂÖ∂ÊøÄËøõÁöÑÊ£ÄÊµã
  const performUltraAggressiveDetection = async (img: HTMLImageElement, canvas: HTMLCanvasElement): Promise<PlateDetection[]> => {
    if (typeof cv === 'undefined') return [];
    
    console.log('üö® Ultra Aggressive Detection (Last Resort)');
    const detections: PlateDetection[] = [];
    let src: any, gray: any, blurred: any, thresh: any, contours: any, hierarchy: any;
    
    try {
      src = cv.imread(img);
      gray = new cv.Mat();
      blurred = new cv.Mat();
      thresh = new cv.Mat();
      contours = new cv.MatVector();
      hierarchy = new cv.Mat();
      
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
      cv.GaussianBlur(gray, blurred, new cv.Size(9, 9), 0); // Heavy blur
      cv.threshold(blurred, thresh, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU); // Aggressive threshold
      
      cv.findContours(thresh, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
      
      for (let i = 0; i < contours.size(); i++) {
        const contour = contours.get(i);
        const rect = cv.boundingRect(contour);
        
        const aspectRatio = rect.width / rect.height;
        const area = rect.width * rect.height;
        const imageArea = img.naturalWidth * img.naturalHeight;
        const relativeArea = area / imageArea;

        // Extremely loose criteria
        if (aspectRatio >= 0.5 && aspectRatio <= 15.0 && // Very, very broad aspect ratio
            relativeArea >= 0.00001 && relativeArea <= 0.2 && // Very, very broad size
            rect.width >= 10 && rect.height >= 3) { // Minimal dimensions
          
          detections.push({
            x: rect.x,
            y: rect.y,
            width: rect.width,
            height: rect.height,
            confidence: 0.1, // Minimal confidence
            method: 'ultra-aggressive',
            angle: 0,
            textScore: 0.1,
            geometryScore: 0.1
          });
        }
        contour.delete();
      }
      
    } catch (err) {
      console.error('Ultra aggressive detection error:', err);
    } finally {
      src?.delete();
      gray?.delete();
      blurred?.delete();
      thresh?.delete();
      contours?.delete();
      hierarchy?.delete();
    }
    
    return detections;
  };

  // ÂêàÂπ∂ÂíåËøáÊª§ÈáçÂ§çÊ£ÄÊµã
  const combineAndFilterDetections = (allDetections: PlateDetection[]): PlateDetection[] => {
    const finalDetections: PlateDetection[] = [];
    
    // In debug mode, apply less strict filtering
    const minConfidence = debugMode ? 0.3 : 0.6;
    const maxResults = debugMode ? 15 : 5;
    const iouThreshold = debugMode ? 0.7 : 0.5; // Less overlap filtering in debug mode
    
    const filteredDetections = allDetections.filter(d => d.confidence >= minConfidence);
    const sortedDetections = [...filteredDetections].sort((a, b) => b.confidence - a.confidence);

    if (debugMode) {
      console.log(`üîç Combining ${allDetections.length} total detections, ${filteredDetections.length} above ${minConfidence} confidence`);
    }

    for (const newDetection of sortedDetections) {
      let isDuplicate = false;
      for (const existingDetection of finalDetections) {
        const iou = calculateIoU(
          [newDetection.x, newDetection.y, newDetection.width, newDetection.height],
          [existingDetection.x, existingDetection.y, existingDetection.width, existingDetection.height]
        );
        if (iou > iouThreshold) {
          isDuplicate = true;
          break;
        }
      }
      if (!isDuplicate && finalDetections.length < maxResults) {
        finalDetections.push(newDetection);
      }
    }
    
    if (debugMode) {
      console.log(`üéØ Final combined results: ${finalDetections.length} unique detections`);
      finalDetections.forEach((d, i) => {
        console.log(`  ${i+1}. [${d.x}, ${d.y}, ${d.width}, ${d.height}] confidence: ${d.confidence.toFixed(2)} method: ${d.method}`);
      });
    }
    
    return finalDetections;
  };

  // Image deletion handler
  // Handle multiple image selection for batch processing
  const toggleImageSelection = (imgId: string, event: React.MouseEvent) => {
    event.stopPropagation();
    setSelectedImages(prev => {
      if (prev.includes(imgId)) {
        return prev.filter(id => id !== imgId);
      } else {
        return [...prev, imgId];
      }
    });
  };

  // Process all selected images
  const processSelectedImages = async () => {
    if (selectedImages.length === 0) {
      setError('Please select at least one image to process.');
      return;
    }

    console.log(`Starting batch processing of ${selectedImages.length} images:`, selectedImages);
    
    // Create a copy of selectedImages to avoid state changes affecting the loop
    const imagesToProcess = [...selectedImages];
    
    // Process images sequentially to avoid overwhelming the system
    for (let i = 0; i < imagesToProcess.length; i++) {
      const imgId = imagesToProcess[i];
      console.log(`Processing image ${i + 1}/${imagesToProcess.length}: ${imgId}`);
      
      try {
        await processImage(imgId);
        console.log(`Completed processing image ${i + 1}/${imagesToProcess.length}: ${imgId}`);
        
        // Add a small delay between processing to prevent browser lockup
        if (i < imagesToProcess.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 500));
        }
      } catch (error) {
        console.error(`Failed to process image ${imgId}:`, error);
        // Continue with next image even if one fails
      }
    }

    console.log('Batch processing completed');
    
    // After processing, update the preview to show the first processed image
    setImages(currentImages => {
      const firstProcessedImage = currentImages.find(img => img.id === imagesToProcess[0]);
      if (firstProcessedImage && firstProcessedImage.processedDataUrl) {
        setSelectedImage(firstProcessedImage);
        setShowOriginal(false); // Show processed result
      }
      return currentImages;
    });
  };

  // Select all images
  const selectAllImages = () => {
    setSelectedImages(images.map(img => img.id));
  };

  // Clear selection
  const clearSelection = () => {
    setSelectedImages([]);
  };

  const handleDelete = (imgId: string) => {
    setImages(prevImages => {
      const imageToDelete = prevImages.find(img => img.id === imgId);
      if (imageToDelete) {
        URL.revokeObjectURL(imageToDelete.originalUrl);
        if (imageToDelete.processedDataUrl) {
          URL.revokeObjectURL(imageToDelete.processedDataUrl);
        }
      }
      return prevImages.filter(img => img.id !== imgId);
    });
    
    // Remove from selected images if it was selected
    setSelectedImages(prev => prev.filter(id => id !== imgId));
    
    // Deselect image after deletion if it was the preview image
    if (selectedImage?.id === imgId) {
      setSelectedImage(null);
    }
  };

  // JSX for the component
  return (
    <Container maxWidth="lg" style={{ padding: '20px' }}>
      <Box sx={{ my: 4, textAlign: 'center' }}>
        <Typography variant="h4" component="h1" gutterBottom>
          AI-Powered Image Anonymizer
        </Typography>
        <Typography variant="subtitle1" gutterBottom>
          Blur or mosaic faces and license plates in your images with advanced detection.
        </Typography>
      </Box>

      {error && (
        <Alert severity="error" sx={{ mb: 2 }}>
          {error}
        </Alert>
      )}

      {!modelsLoaded && (
        <Box sx={{ display: 'flex', justifyContent: 'center', alignItems: 'center', flexDirection: 'column', my: 4 }}>
          <CircularProgress />
          <Typography variant="h6" sx={{ mt: 2 }}>Loading AI Models...</Typography>
          <Typography variant="body2">This may take a moment depending on your connection speed.</Typography>
        </Box>
      )}

      {modelsLoaded && (
        <Grid container spacing={3}>
          <Grid item xs={12} md={4}>
            <Paper elevation={3} sx={{ p: 2, height: '100%' }}>
              <Stack spacing={2}>
                <Typography variant="h6">Upload Images</Typography>
                <input
                  accept="image/*"
                  style={{ display: 'none' }}
                  id="image-upload-button"
                  multiple
                  type="file"
                  onChange={handleImageUpload}
                />
                <label htmlFor="image-upload-button">
                  <Button variant="contained" component="span" startIcon={<CloudUpload />} fullWidth>
                    Upload Images
                  </Button>
                </label>
                {/* Batch Processing Controls */}
                <Box sx={{ mb: 2 }}>
                  <Typography variant="h6" gutterBottom>
                    Batch Processing ({selectedImages.length} selected)
                  </Typography>
                  
                  <Stack spacing={1}>
                    <Stack direction="row" spacing={1}>
                      <Button 
                        variant="contained" 
                        onClick={processSelectedImages}
                        disabled={selectedImages.length === 0 || images.some(img => selectedImages.includes(img.id) && img.processing)}
                        fullWidth
                        sx={{ flex: 2 }}
                      >
                        {images.some(img => selectedImages.includes(img.id) && img.processing) ? (
                          <>
                            <CircularProgress size={20} sx={{ mr: 1 }} />
                            Processing...
                          </>
                        ) : (
                          `Process ${selectedImages.length} Image${selectedImages.length !== 1 ? 's' : ''}`
                        )}
                      </Button>
                    </Stack>
                    
                    <Stack direction="row" spacing={1}>
                      <Button 
                        variant="outlined" 
                        size="small"
                        onClick={selectAllImages}
                        disabled={images.length === 0}
                      >
                        Select All
                      </Button>
                      <Button 
                        variant="outlined" 
                        size="small"
                        onClick={clearSelection}
                        disabled={selectedImages.length === 0}
                      >
                        Clear Selection
                      </Button>
                    </Stack>
                  </Stack>
                </Box>
                <Divider />
                <Typography variant="h6">Detection Settings</Typography>
                <FormControlLabel
                  control={
                    <Switch
                      checked={enableFaceDetection}
                      onChange={(e) => setEnableFaceDetection(e.target.checked)}
                      name="faceDetection"
                    />
                  }
                  label="Enable Face Detection"
                />
                <FormControlLabel
                  control={
                    <Switch
                      checked={enablePlateDetection}
                      onChange={(e) => setEnablePlateDetection(e.target.checked)}
                      name="plateDetection"
                    />
                  }
                  label="Enable License Plate Detection"
                />
                <FormControlLabel
                  control={
                    <Switch
                      checked={debugMode}
                      onChange={(e) => setDebugMode(e.target.checked)}
                      name="debugMode"
                    />
                  }
                  label="üêõ Debug Mode (Show Console Logs)"
                />
                <FormControlLabel
                  control={
                    <Switch
                      checked={highlightMode}
                      onChange={(e) => setHighlightMode(e.target.checked)}
                      name="highlightMode"
                    />
                  }
                  label="üé® Highlight Mode (Testing - Use Color Instead of Blur/Mosaic)"
                />
                {highlightMode && (
                  <Box sx={{ mt: 1, mb: 2 }}>
                    <Typography gutterBottom>Highlight Color:</Typography>
                    <Stack direction="row" spacing={2} alignItems="center">
                      <input
                        type="color"
                        value={highlightColor}
                        onChange={(e) => setHighlightColor(e.target.value)}
                        style={{
                          width: 50,
                          height: 40,
                          border: '2px solid #ccc',
                          borderRadius: '8px',
                          cursor: 'pointer'
                        }}
                      />
                      <Typography variant="body2" color="text.secondary">
                        Selected: {highlightColor.toUpperCase()}
                      </Typography>
                    </Stack>
                  </Box>
                )}
                <Typography gutterBottom>Detection Method:</Typography>
                <Stack direction="row" spacing={1} sx={{ flexWrap: 'wrap' }}>
                  {[
                    {key: 'robust', label: 'üí™ Robust', desc: 'Multi-method combination'},
                    {key: 'simple', label: 'üéØ Simple', desc: 'Fast & effective'},
                    {key: 'aggressive', label: 'üî• Aggressive', desc: 'Loose criteria for difficult images'},
                    {key: 'australian', label: 'üá¶üá∫ Australian', desc: 'Optimized for AU plates'},
                    {key: 'plateRecognizer', label: 'üì∏ AI Service', desc: 'Professional API'}
                  ].map((method) => (
                    <Chip
                      key={method.key}
                      label={method.label}
                      color={detectionMethod === method.key ? 'primary' : 'default'}
                      onClick={() => setDetectionMethod(method.key as any)}
                      sx={{ mb: 1 }}
                      title={method.desc}
                    />
                  ))}
                </Stack>
                
                {/* Detection Method Description */}
                <Typography variant="caption" color="text.secondary" sx={{ mt: 1, display: 'block' }}>
                  {detectionMethod === 'robust' && 'üí™ Uses multiple detection algorithms for highest accuracy'}
                  {detectionMethod === 'simple' && 'üéØ Fast single-method detection with good balance'}
                  {detectionMethod === 'aggressive' && 'üî• Very loose criteria - detects everything that might be a plate'}
                  {detectionMethod === 'australian' && 'üá¶üá∫ Specialized for Australian license plate standards (372√ó134mm)'}
                  {detectionMethod === 'plateRecognizer' && 'üì∏ Professional cloud-based AI service (requires API key)'}
                </Typography>
                {detectionMethod === 'plateRecognizer' && (
                  <TextField
                    label="Plate Recognizer API Key"
                    variant="outlined"
                    value={plateRecognizerApiKey}
                    onChange={(e) => setPlateRecognizerApiKey(e.target.value)}
                    fullWidth
                    margin="normal"
                  />
                )}
                
                {/* Testing Instructions */}
                <Alert severity="info" sx={{ mt: 2 }}>
                  <Typography variant="subtitle2" gutterBottom>üß™ Testing Different Images:</Typography>
                  <Typography variant="caption" component="div">
                    ‚Ä¢ <strong>Easy images:</strong> Try "Simple" or "Robust" method<br/>
                    ‚Ä¢ <strong>Difficult lighting/angles:</strong> Try "Aggressive" method<br/>
                    ‚Ä¢ <strong>Australian plates:</strong> Use "Australian" method<br/>
                    ‚Ä¢ <strong>No detection:</strong> Enable Debug Mode to see console logs<br/>
                    ‚Ä¢ <strong>Professional accuracy:</strong> Use "AI Service" with API key
                  </Typography>
                </Alert>
                <Divider />
                <Typography variant="h6">Anonymization Settings</Typography>
                <FormControlLabel
                  control={
                    <Switch
                      checked={blur}
                      onChange={(e) => setBlur(e.target.checked)}
                      name="blurEffect"
                    />
                  }
                  label="Apply Blur"
                />
                {blur && (
                  <Box>
                    <Typography gutterBottom>Blur Amount: {blurAmount}%</Typography>
                    <Slider
                      value={blurAmount}
                      onChange={(e, newValue) => setBlurAmount(newValue as number)}
                      aria-labelledby="blur-amount-slider"
                      valueLabelDisplay="auto"
                      min={0}
                      max={100}
                    />
                  </Box>
                )}
                <FormControlLabel
                  control={
                    <Switch
                      checked={mosaic}
                      onChange={(e) => setMosaic(e.target.checked)}
                      name="mosaicEffect"
                    />
                  }
                  label="Apply Mosaic"
                />
                {mosaic && (
                  <Box>
                    <Typography gutterBottom>Mosaic Pixel Size: {mosaicAmount}</Typography>
                    <Slider
                      value={mosaicAmount}
                      onChange={(e, newValue) => setMosaicAmount(newValue as number)}
                      aria-labelledby="mosaic-amount-slider"
                      valueLabelDisplay="auto"
                      min={4}
                      max={30}
                    />
                  </Box>
                )}
                <Box>
                  <Typography gutterBottom>Plate Opacity: {Math.round(plateOpacity * 100)}%</Typography>
                  <Slider
                    value={plateOpacity * 100}
                    onChange={(e, newValue) => setPlateOpacity((newValue as number) / 100)}
                    aria-labelledby="plate-opacity-slider"
                    valueLabelDisplay="auto"
                    min={0}
                    max={100}
                  />
                </Box>
                <FormControlLabel
                  control={
                    <Switch
                      checked={debugMode}
                      onChange={(e) => setDebugMode(e.target.checked)}
                      name="debugMode"
                    />
                  }
                  label="Debug Mode (Show Bounding Boxes)"
                />
              </Stack>
            </Paper>
          </Grid>

          <Grid item xs={12} md={8}>
            <Paper elevation={3} sx={{ p: 2, height: '100%', display: 'flex', flexDirection: 'column' }}>
              <Typography variant="h6" gutterBottom>Image Preview</Typography>
              {selectedImage ? (
                <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'center', alignItems: 'center', position: 'relative', minHeight: 300 }}>
                  <Card raised sx={{ maxWidth: '100%', maxHeight: 600, display: 'flex', flexDirection: 'column' }}>
                    <CardMedia
                      component="img"
                      image={showOriginal ? selectedImage.originalUrl : (selectedImage.processedDataUrl || selectedImage.originalUrl)}
                      alt={selectedImage.fileName}
                      sx={{ 
                        maxWidth: '100%', 
                        height: 'auto', 
                        objectFit: 'contain',
                        display: 'block',
                        filter: 'none' // Blur is applied only to detected regions in processImage function
                      }}
                    />
                    <CardContent>
                      <Typography variant="subtitle1">{selectedImage.fileName}</Typography>
                      <Typography variant="body2" color="text.secondary">
                        {selectedImage.processing ? 'Processing...' : selectedImage.detectionInfo}
                      </Typography>
                      {selectedImage.processing && (
                        <LinearProgress sx={{ mt: 1 }} />
                      )}
                      <Stack direction="row" spacing={1} sx={{ mt: 2, flexWrap: 'wrap' }}>
                        <Button 
                          variant="outlined" 
                          size="small" 
                          onClick={() => setShowOriginal(!showOriginal)}
                          startIcon={showOriginal ? <Visibility /> : <Visibility />}
                        >
                          {showOriginal ? 'Show Processed' : 'Show Original'}
                        </Button>
                        <IconButton aria-label="download" size="small" href={selectedImage.processedDataUrl || selectedImage.originalUrl} download={selectedImage.fileName.replace(/(\.[\w\d_-]+)$/i, '_anonymized$1')}>
                          <Download />
                        </IconButton>
                        <IconButton aria-label="delete" size="small" onClick={() => handleDelete(selectedImage.id)}>
                          <Delete />
                        </IconButton>
                      </Stack>
                      {debugMode && selectedImage.detectedRegions.length > 0 && (
                        <Box sx={{ mt: 2 }}>
                          <Typography variant="subtitle2">Detected Regions:</Typography>
                          <Grid container spacing={1}>
                            {selectedImage.detectedRegions.map(region => (
                              <Grid item key={region.id}>
                                <Chip 
                                  label={`${region.type} (${region.confidence.toFixed(2)})`} 
                                  color={region.enabled ? 'success' : 'default'} 
                                  variant={region.enabled ? 'filled' : 'outlined'}
                                  onClick={() => {
                                    setImages(prev => prev.map(img => 
                                      img.id === selectedImage.id 
                                        ? { 
                                            ...img, 
                                            detectedRegions: img.detectedRegions.map(r => 
                                              r.id === region.id ? { ...r, enabled: !r.enabled } : r
                                            )
                                          } 
                                        : img
                                    ));
                                    // Re-process image to apply/remove effect
                                    processImage(selectedImage.id);
                                  }}
                                />
                              </Grid>
                            ))}
                          </Grid>
                        </Box>
                      )}
                    </CardContent>
                  </Card>
                </Box>
              ) : (
                <Box sx={{ flexGrow: 1, display: 'flex', justifyContent: 'center', alignItems: 'center' }}>
                  <Typography variant="h6" color="text.secondary">No image selected</Typography>
                </Box>
              )}
            </Paper>
          </Grid>
        </Grid>
      )}

      <Box sx={{ my: 4 }}>
        <Stack direction="row" alignItems="center" justifyContent="space-between" sx={{ mb: 2 }}>
          <Typography variant="h5">Image Gallery</Typography>
          {selectedImages.length > 0 && (
            <Chip 
              label={`${selectedImages.length} selected`}
              color="primary"
              variant="outlined"
              size="small"
            />
          )}
        </Stack>
        <Grid container spacing={2}>
          {images.map(img => (
            <Grid item key={img.id} xs={12} sm={6} md={3}>
              <Card 
                onClick={() => {
                  setSelectedImage(img);
                  // If the selected image has been processed, show processed version by default
                  if (img.processedDataUrl) {
                    setShowOriginal(false);
                  }
                }} 
                sx={{ 
                  cursor: 'pointer', 
                  border: selectedImages.includes(img.id) ? '2px solid #2196f3' : 
                          (img.id === selectedImage?.id ? '2px solid primary.main' : '1px solid #e0e0e0'),
                  boxShadow: selectedImages.includes(img.id) ? 3 : 
                             (img.id === selectedImage?.id ? 5 : 1),
                  position: 'relative'
                }}
              >
                {/* Multi-selection checkbox in top-right corner */}
                <Box
                  onClick={(e) => toggleImageSelection(img.id, e)}
                  sx={{
                    position: 'absolute',
                    top: 8,
                    right: 8,
                    zIndex: 10,
                    bgcolor: 'rgba(255, 255, 255, 0.9)',
                    borderRadius: '50%',
                    width: 26,
                    height: 26,
                    display: 'flex',
                    alignItems: 'center',
                    justifyContent: 'center',
                    cursor: 'pointer',
                    '&:hover': {
                      bgcolor: 'rgba(255, 255, 255, 1)',
                      transform: 'scale(1.1)'
                    }
                  }}
                >
                  {selectedImages.includes(img.id) ? (
                    <CheckCircle sx={{ color: '#2196f3', fontSize: 22 }} />
                  ) : (
                    <RadioButtonUnchecked sx={{ color: 'grey.400', fontSize: 22 }} />
                  )}
                </Box>

                {/* Preview indicator in top-left if this is the main preview image */}
                {img.id === selectedImage?.id && (
                  <Box
                    sx={{
                      position: 'absolute',
                      top: 8,
                      left: 8,
                      zIndex: 10,
                      bgcolor: 'rgba(76, 175, 80, 0.9)',
                      borderRadius: '12px',
                      px: 1,
                      py: 0.5
                    }}
                  >
                    <Typography variant="caption" sx={{ color: 'white', fontSize: '10px', fontWeight: 'bold' }}>
                      PREVIEW
                    </Typography>
                  </Box>
                )}
                <CardMedia
                  component="img"
                  height="140"
                  image={img.processedDataUrl || img.originalUrl}
                  alt={img.fileName}
                  sx={{ objectFit: 'cover' }}
                />
                <CardContent>
                  <Typography variant="subtitle2" noWrap>{img.fileName}</Typography>
                  <Typography variant="body2" color="text.secondary">
                    {img.processing ? 'Processing...' : img.detectionInfo || 'Not processed'}
                  </Typography>
                  <Stack direction="row" spacing={1} sx={{ mt: 1 }}>
                    <IconButton aria-label="process" size="small" onClick={(e) => { e.stopPropagation(); processImage(img.id); }} disabled={img.processing}>
                      <Settings fontSize="small" />
                    </IconButton>
                    <IconButton aria-label="delete" size="small" onClick={(e) => { e.stopPropagation(); handleDelete(img.id); }}>
                      <Delete fontSize="small" />
                    </IconButton>
                  </Stack>
                </CardContent>
              </Card>
            </Grid>
          ))}
        </Grid>
      </Box>
    </Container>
  );
};

export default App;
